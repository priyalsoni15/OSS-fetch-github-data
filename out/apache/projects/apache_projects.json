[
    {
        "name": "Apache Accumulo",
        "description": "The Apache Accumulo sorted, distributed key/value store is\n      based on Google's BigTable design. It is built on top of Apache Hadoop,\n      Apache Zookeeper, and Apache Thrift. It features a few novel improvements\n      on the BigTable design in the form of cell-level access labels and a\n      server-side programming mechanism that can modify key/value pairs at\n      various points in the data management process.",
        "homepage": "https://accumulo.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ActiveMQ",
        "description": "ActiveMQ is a fast and powerful Message Broker which supports many Cross Language Clients and Protocols and many advanced features while fully supporting JMS 1.1 and J2EE 1.4.",
        "homepage": "http://activemq.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache AGE",
        "description": "The goal of Apache AGE\u2122 is to provide graph data processing and analytics capability to all relational databases.\n\nThrough Apache AGE, PostgreSQL users will gain access to graph query modeling within the existing relational database.\n",
        "homepage": "https://age.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Airavata",
        "description": "Apache Airavata is a micro-service architecture based software framework for\n            executing and managing computational jobs and workflows on distributed computing\n            resources including local clusters, supercomputers, national grids, academic and\n            commercial clouds. Airavata is dominantly used to build Web-based science gateways and\n            assist to compose, manage, execute, and monitor large scale applications (wrapped as Web\n            services) and workflows composed of these services.",
        "homepage": "http://airavata.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, cloud, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Airflow",
        "description": "The mission of Apache Airflow is the creation and maintenance of software\nrelated to workflow automation and scheduling that can be used to author and\nmanage data pipelines.\n",
        "homepage": "https://airflow.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Allura",
        "description": "Apache Allura is an open source implementation of a software \"forge\", a web site that manages source code repositories, bug reports, discussions, wiki pages, blogs and more for any number of individual projects.",
        "homepage": "http://allura.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Ambari",
        "description": "Apache Ambari makes Hadoop cluster provisioning, managing, and monitoring dead simple.",
        "homepage": "http://ambari.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Ant",
        "description": "Apache Ant is a Java-based build tool.",
        "homepage": "http://ant.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache AntUnit",
        "description": "The Ant Library provides Ant tasks for testing Ant\n      task, it can also be used to drive functional and integration tests\n      of arbitrary applications with Ant.",
        "homepage": "http://ant.apache.org/antlibs/antunit/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management, testing",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Compress Ant Library",
        "description": "This is a library of Ant tasks and types uses Apache\n      Commons Compress to support additional archive formats like ar,\n      pack200, xz and cpio.",
        "homepage": "http://ant.apache.org/antlibs/compress/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache .NET Ant Library",
        "description": "This is a library of Ant tasks that help developing\n.NET software.  It includes the \"old\" .NET tasks like a C# compiler task but also comes with support for NUnit testing or running the popular NAnt or MSBuild build tools.",
        "homepage": "http://ant.apache.org/antlibs/dotnet/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Ivy",
        "description": "Apache Ivy is a very powerful dependency manager oriented toward Java dependency management, even though it could be used to manage dependencies of any kind.",
        "homepage": "http://ant.apache.org/ivy/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache IvyDE",
        "description": "The now retired IvyDE lets you manage your dependencies declared in an ivy.xml in your Java Eclipse projects. IvyDE will contribute to the classpath of your Java project, with the classpath container. It also bring an editor of ivy.xml files, with completion.",
        "homepage": "http://ant.apache.org/ivyde/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Props Ant Library",
        "description": "The Apache Props Antlib is a library of supplementary handlers for Apache Ant properties resolution.\n\nThe types provided are instances of org.apache.tools.ant.PropertyHelper.Delegate and can be invoked using the <propertyhelper> task provided in Ant 1.8.0.",
        "homepage": "http://ant.apache.org/antlibs/props/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache VSS Ant Library",
        "description": "The Apache VSS Antlib provides an interface to the Microsoft Visual SourceSafe SCM. The original Ant tasks have been expanded upon in this Antlib. Some fixes to issues in the original tasks have also been incorporated.",
        "homepage": "http://ant.apache.org/antlibs/proper.html",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Portable Runtime",
        "description": "\nThe mission of the Apache Portable Runtime (APR) project is to create\nand maintain software libraries that provide a predictable and\nconsistent interface to underlying platform-specific implementations.\nThe primary goal is to provide an API to which software developers may\ncode and be assured of predictable if not identical behaviour\nregardless of the platform on which their software is built, relieving\nthem of the need to code special-case conditions to work around or\ntake advantage of platform-specific deficiencies or features.\n    ",
        "homepage": "https://apr.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Aries",
        "description": "The Aries project is delivering a set of pluggable Java components enabling an enterprise OSGi application programming model. This includes implementations and extensions of application-focused specifications defined by the OSGi Alliance Enterprise Expert Group (EEG) and an assembly format for multi-bundle applications, for deployment to a variety of OSGi based runtimes.",
        "homepage": "https://aries.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Arrow",
        "description": "Apache Arrow defines a language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware like CPUs and GPUs. The Arrow memory format also supports zero-copy reads for lightning-fast data access without serialization overhead.\n\nArrow's libraries implement the format and provide building blocks for a range of use cases, including high performance analytics. Many popular projects use Arrow to ship columnar data efficiently or as the basis for analytic engines.\n\nLibraries are available for C, C++, C#, Go, Java, JavaScript, Julia, MATLAB, Python, R, Ruby, and Rust.\n\nApache Arrow is software created by and for the developer community. We are dedicated to open, kind communication and consensus decision making. Our committers come from a range of organizations and backgrounds, and we welcome all to participate with us.",
        "homepage": "https://arrow.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database, data-engineering, library, network-client, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Any23",
        "description": "Apache Any23 is used in major Web of Data applications. It is written in Java and licensed under the Apache License v2.0. Apache Any23 can be used in various ways:\n* As a library in Java applications that consume structured data from the Web.\n* As a command-line tool for extracting and converting between the supported formats.\n* As online service API available at any23.org.",
        "homepage": "http://any23.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Apex",
        "description": "Apache Apex is a unified platform for big data stream and batch processing. Use cases include ingestion, ETL, real-time analytics, alerts and real-time actions. Apex is a Hadoop-native YARN implementation and uses HDFS by default. It simplifies development and productization of Hadoop applications by reducing time to market. Key features include Enterprise Grade Operability with Fault Tolerance, State Management, Event Processing Guarantees, No Data Loss, In-memory Performance & Scalability and Native Window Support.",
        "homepage": "http://apex.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Archiva",
        "description": "Archiva is the perfect companion for build tools such as Maven, Continuum, and ANT. Archiva offers several capabilities, amongst which remote repository proxying,\nsecurity access management, build artifact storage, delivery, browsing, indexing and usage reporting, extensible scanning functionality and many more!",
        "homepage": "https://archiva.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Beehive",
        "description": "Our goal is to make J2EE programming easier by building a simple object model on J2EE and Struts. Using Java 5 annotations, Beehive reduces the coding necessary for J2EE. The initial Beehive project has three pieces.\n\nNetUI: An annotation-driven web application programming framework that is built atop Struts. NetUI centralizes navigation logic, state, metadata, and exception handling in a single encapsulated and reusable Page Flow Controller class. In addition, NetUI provides a set of JSP tags for rendering HTML / XHTML and higher-level UI constructs such as data grids and trees and has first-class integration with JavaServer Faces and Struts.\n \nControls: A lightweight, metadata-driven component framework that reduces the complexity of being a client of enterprise resources. Controls provide a unified client abstraction that can be implemented to access a diverse set of enterprise resources using a single configuration model.\n\nWeb Service Metadata (WSM): An implementation of JSR 181 which standardizes a simplified, annotation-driven model for building Java web services.\n\nIn addition, Beehive includes a set of system controls that are abstractions for low-level J2EE resource APIs such as EJB, JMS, JDBC, and web services.",
        "homepage": "http://beehive.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Buildr",
        "description": "We wanted something that's simple and intuitive to use, so we only need to tell it what to do, and it takes care of the rest.  But also something we can easily extend for those one-off tasks, with a language that's a joy to use.",
        "homepage": "http://buildr.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Chemistry",
        "description": "Apache Chemistry provides open source implementations of the Content Management Interoperability Services (CMIS) specification. Libraries are available for Java, Python, PHP and .NET.",
        "homepage": "http://chemistry.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Chukwa",
        "description": "\n      Chukwa is an open source data collection system for monitoring \n      large distributed systems. Chukwa is built on top of \n      the Hadoop Distributed File System (HDFS) and Map/Reduce framework \n      and inherits Hadoop\u2019s scalability and robustness. Chukwa also includes \n      a \ufb02exible and powerful toolkit for displaying, monitoring and analyzing \n      results to make the best use of the collected data.\n    ",
        "homepage": "http://chukwa.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, hadoop",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Clerezza",
        "description": "Clerezza allows to easily develop semantic web applications by providing tools to manipulate RDF data, create RESTful Web Services and Renderlets using ScalaServerPages. Contents are stored as triples based on W3C RDF specification. These triples are stored via Clerezza\u2019s Smart Content Binding (SCB). SCB defines a technology-agnostic layer to access and modify triple stores. It provides a java implementation of the graph data model specified by W3C RDF and functionalities to operate on that data model. SCB offers a service interface to access multiple named graphs and it can use various providers to manage RDF graphs in a technology specific manner, e.g., using Jena or Sesame. It also provides for adaptors that allow an application to use various APIs (including the Jena api) to process RDF graphs. Furthermore, SCB offers a serialization and a parsing service to convert a graph into a certain representation (format) and vice versa.",
        "homepage": "http://clerezza.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, osgi, content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Click",
        "description": "Apache Click is a modern Java web application framework, providing\n    a natural rich client style programming model. Click provides a page and\n    component oriented design with a event based programming model. Leveraging\n    a stateless architecture Click encourages loosely coupled pages for\n    easier maintenance. Click is designed to be very easy to learn and use, with\n    developers getting up and running within a day. Support is provided for Velocity,\n    JSP or FreeMarker page rendering. Click also provides exceptional performance\n    for high volume web sites.\n    ",
        "homepage": "http://click.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, library, network-server, network-client, xml, web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Continuum",
        "description": "Whether you have a centralized build team or want to put control of releases in the hands of developers, Apache Continuum can help you improve quality and maintain a consistent build environment. Follow us on Twitter @apachecontinuum to get the latest news and updates!",
        "homepage": "http://continuum.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Crunch",
        "description": "The Apache Crunch Java library provides a framework for writing, testing, and running MapReduce pipelines. Its goal is to make pipelines that are composed of many user-defined functions simple to write, easy to test, and efficient to run.\n\nRunning on top of Hadoop MapReduce and Apache Spark, the Apache Crunch\u2122 library is a simple Java API for tasks like joining and data aggregation that are tedious to implement on plain MapReduce. The APIs are especially useful when processing data that does not fit naturally into relational model, such as time series, serialized object formats like protocol buffers or Avro records, and HBase rows and columns. For Scala users, there is the Scrunch API, which is built on top of the Java APIs and includes a REPL (read-eval-print loop) for creating MapReduce pipelines.",
        "homepage": "http://crunch.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Deltacloud",
        "description": "Deltacloud contains a cloud abstraction API - whether the Deltacloud classic API, the DMTF CIMI API or even the EC2 API. Each abstraction API works as a wrapper around a large number of clouds, shielding users from their differences. For every cloud provider there is a driver \"speaking\" that cloud provider's native API, freeing you from dealing with the particulars of each cloud's API.",
        "homepage": "http://deltacloud.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud, library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache DeviceMap",
        "description": "Apache Devicemap is a data repository containing devices attributes, and their related browsers, and operating systems. The project also maintains an api to classify these attributes. ",
        "homepage": "http://devicemap.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "mobile, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache DirectMemory",
        "description": "Apache DirectMemory is a off-heap cache for the Java Virtual Machine",
        "homepage": "http://directmemory.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ECS",
        "description": "The Element Construction Set is a Java API for generating elements for various markup languages it directly supports HTML 4.0 and XML, but can easily be extended to create tags for any markup language.",
        "homepage": "http://jakarta.apache.org/ecs/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ESME",
        "description": "Apache ESME (Enterprise Social Messaging Environment) is a secure and highly scalable microsharing and micromessaging platform that allows people to discover and meet one another and get controlled access to other sources of information, all in a business process context.   \nYou can hardly turn a web page these days without seeing a story that describes how people are using social networks, whether it is Twitter, Facebook or some other service to develop and build their personal communities. In business, we increasingly see blogs and wikis demonstrating utility in problem solving and communications but the real time nature of business process problem solving largely remains untouched by social networking tools. Existing services, while attractive do not scale well and have proven unreliable. This is unacceptable to business which must be 'Always On' and able to support people in their daily working lives. Such applications must therefore be scalable and reliable but also provide a lot more.\nWhen solving problems, how good might it be if a user was able to tap into the collective knowledge of her peers or surrounding groups of people with whom she might naturally network in the workplace setting? How much quicker and with greater precision might she be able to solve daily problems? What if there was a communications mechanism that takes the best of what services like Twitter offers and co-mingled that with readily recognizable business processes? That solution is Apache ESME.",
        "homepage": "http://esme.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Etch",
        "description": "Etch is a cross-platform, language- and transport-independent framework for building and consuming network services. The Etch toolset includes a network service description language, a compiler, and binding libraries for a variety of programming languages. Etch is also transport-independent, allowing for a variety of different transports to be used based on need and circumstance. The goal of Etch is to make it simple to define small, focused services that can be easily accessed, combined, and deployed in a similar manner. With Etch, service development and consumption becomes no more difficult than library development and consumption.",
        "homepage": "http://etch.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, network-client, library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Excalibur",
        "description": "The predecessor of Apache Avalon, Apache Excalibur hosts the Avalon framework, a Java container framework, the Excalibur and Fortress inversion of control containers, and a rich library of components.  Excalibur code powers Apache James and Cocoon and numerous other open source and commercial projects.",
        "homepage": "http://excalibur.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Falcon",
        "description": "Apache Falcon is a data processing and management solution for Hadoop designed for data motion, coordination of data pipelines, lifecycle management, and data discovery. Falcon enables end consumers to quickly onboard their data and its associated processing and management tasks on Hadoop clusters.",
        "homepage": "http://falcon.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Forrest",
        "description": "\n      Apache Forrest\u2122 software is a publishing framework that transforms\n      input from various sources into a unified presentation in one or more\n      output formats. The modular and extensible plug-in architecture of\n      Apache Forrest is based on Apache Cocoon and the relevant industry\n      standards that separate presentation from content. Forrest can generate\n      static documents, or be used as a dynamic server, or be deployed by its\n      automated facility.\n    ",
        "homepage": "http://forrest.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, build-management, database, graphics, http, network-client, network-server, web-framework, xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Giraph",
        "description": "Apache Giraph is an iterative graph processing system built for high scalability. For example, it is currently used at Facebook to analyze the social graph formed by users and their connections. ",
        "homepage": "http://giraph.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Hama",
        "description": "The Apache Hama is an efficient and scalable general-purpose BSP computing engine which can be used to speed up a large variety of compute-intensive analytics applications.",
        "homepage": "http://hama.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Harmony",
        "description": " Apache Harmony software is a modular Java runtime with class libraries and associated tools.\n    ",
        "homepage": "http://harmony.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "virtual-machine, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Hivemind",
        "description": "HiveMind is a framework for creating applications, not an application, or even an application server, itself. The 'core' of HiveMind is the startup logic that knows how to parse and understand the module deployment descriptors, and use that information to instantiate and initialize all those services and configurations.",
        "homepage": "http://hivemind.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Jakarta Cactus",
        "description": "The intent of Cactus is to lower the cost of writing tests for server-side code. It uses JUnit and extends it.\n\nCactus implements an in-container strategy, meaning that tests are executed inside the container. ",
        "homepage": "http://jakarta.apache.org/cactus",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "testing, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Lens",
        "description": "Lens provides an Unified Analytics interface.\n      Lens aims to cut the Data Analytics silos by providing a single view of data across\n      multiple tiered data stores and optimal execution environment for the analytical query.\n      It seamlessly integrates Hadoop with traditional data warehouses to appear like one.\n    ",
        "homepage": "http://lens.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Lenya",
        "description": "Apache Lenya is an Open Source Java/XML Content Management Framework and comes with revision control, site management, scheduling, search, WYSIWYG editors, and workflow.",
        "homepage": "http://lenya.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, xml, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Lucy",
        "description": "The Apache Lucy search engine library provides full-text search for dynamic programming languages.",
        "homepage": "http://lucy.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Marmotta",
        "description": "The goal of Apache Marmotta is to provide an open implementation of a Linked Data Platform that can be used, extended and deployed easily by organizations who want to publish Linked Data or build custom applications on Linked Data",
        "homepage": "http://marmotta.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache MetaModel",
        "description": "With MetaModel you get a uniform connector and query API to many very different datastore types, including: Relational (JDBC) databases, CSV files, Excel spreadsheets, XML files, JSON files, Fixed width files, MongoDB, Apache CouchDB, Apache HBase, Apache Cassandra, ElasticSearch, OpenOffice.org databases, Salesforce.com, SugarCRM and even collections of plain old Java objects (POJOs).\n\nMetaModel isn't a data mapping framework. Instead we emphasize abstraction of metadata and ability to add data sources at runtime, making MetaModel great for generic data processing applications, less so for applications modeled around a particular domain.",
        "homepage": "http://metamodel.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, big-data, library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache MRUnit",
        "description": "The Apache MRUnit is a Java library that helps developers unit test Apache Hadoop map reduce jobs.",
        "homepage": "http://mrunit.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache MXNet",
        "description": "Apache MXNet is a deep learning framework designed for both efficiency and flexibility. It's lightweight, Portable, Flexible Distributed/Mobile Deep Learning with dynamic, mutation-aware data-flow dependency scheduler; for Python, R, Julia, Scala, Go, Javascript and more",
        "homepage": "https://mxnet.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ODE",
        "description": "Apache ODE (Orchestration Director Engine) executes business processes written following the WS-BPEL standard. It talks to web services, sending and receiving messages, handling data manipulation and error recovery as described by your process definition. It supports both long and short living process executions to orchestrate all the services that are part of your application.\n\nWS-BPEL is an XML-based language defining several constructs to write business processes. It defines a set of basic control structures like conditions or loops as well as elements to invoke web services and receive messages from services. It relies on WSDL to express web services interfaces. Message structures can be manipulated, assigning parts or the whole of them to variables that can in turn be used to send other messages.",
        "homepage": "http://ode.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, xml, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Oltu - Parent",
        "description": "Apache Oltu is an OAuth protocol implementation in Java.",
        "homepage": "https://oltu.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OODT",
        "description": "Apache OODT software is component based, and offers a software architecture beyond simple science applications.",
        "homepage": "http://oodt.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Open Climate Workbench",
        "description": "Apache Open Climate Workbench is an effort to develop software that performs climate model evaluation using model outputs from a variety of different sources (the Earth System Grid Federation, the Coordinated Regional Downscaling Experiment, the U.S. National Climate Assessment and the North American Regional Climate Change Assessment Program) and temporal/spatial scales with remote sensing data from NASA, NOAA and other agencies. The toolkit includes capabilities for rebinning, metrics computation and visualization.",
        "homepage": "http://climate.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ORO",
        "description": "A set of text-processing Java classes that provide Perl5 compatible regular expressions, AWK-like regular expressions, glob expressions, and utility classes for performing substitutions, splits, filtering filenames, etc.",
        "homepage": "http://jakarta.apache.org/oro/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, regexp, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Polygene",
        "description": "Apache Polygene is a community based effort exploring Composite Oriented Programming for domain centric application development. This includes evolved concepts from Aspect Oriented Programming, Dependency Injection and Domain Driven Design. Composite Oriented Programming allows developers to work with 'fragments', smaller than classes, and 'compose' fragments into larger 'composites' which acts like the regular objects. Polygene also tackles the enforcement of application composition, i.e. composites are declared in modules, modules are contained in layers and access between layers are controlled/enforced. Apache Polygene\u2122 (Java Edition), first Apache Polygene sub-project, is an implementation of Composite Oriented Programming, using the standard Java platform, without the use of any pre-processors or new language elements. Everything you know from Java still applies and you can leverage both your experience and toolkits to become more productive with Composite Oriented Programming today.",
        "homepage": "https://polygene.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache PredictionIO",
        "description": "PredictionIO is an open source Machine Learning Server built on top of state-of-the-art open source stack, that enables developers to manage and deploy production-ready predictive services for various kinds of machine learning tasks.",
        "homepage": "http://predictionio.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache REEF",
        "description": "\n      Apache REEF (Retainable Evaluator Execution Framework) is a development\n      framework that provides a control-plane for scheduling and coordinating\n      task-level (data-plane) work on cluster resources obtained from a\n      Resource Manager. REEF provides mechanisms that facilitate resource\n      reuse for data caching, and state management abstractions that greatly\n      ease the development of elastic data processing workflows on cloud\n      platforms that support a Resource Manager service.\n    ",
        "homepage": "http://reef.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Regexp",
        "description": "100% Pure Java Regular Expression package",
        "homepage": "http://jakarta.apache.org/regexp/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, regexp, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache River",
        "description": "Apache River software provides a JINI service, which is a service oriented architecture that defines a programming model which both exploits and extends Java technology to enable the construction of secure, distributed systems consisting of federations of services and clients. Jini technology can be used to build adaptive network systems that are scalable, evolvable and flexible as typically required in dynamic computing environments.",
        "homepage": "http://river.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, javaee",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Shale",
        "description": "Shale is a modern web application framework, fundamentaly based on JavaServer Faces, and focused on improving ease of use for developers adopting JSF as a foundational technology in their own development environments.",
        "homepage": "http://shale.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Shindig",
        "description": "Apache Shindig is a container for hosting social application consisting of four parts:\n\n    Gadget Container JavaScript: core JavaScript foundation for general gadget functionality (read more about gadget functionality). This JavaScript manages security, communication, UI layout, and feature extensions, such as the OpenSocial API.\n    Gadget Rendering Server: used to render the gadget XML into JavaScript and HTML for the container to expose via the container JavaScript.\n    OpenSocial Container JavaScript: JavaScript environment that sits on top of the Gadget Container JavaScript and provides OpenSocial specific functionality (profiles, friends, activities, datastore).\n    OpenSocial Data Server: an implementation of the server interface to container-specific information, including the OpenSocial REST APIs, with clear extension points so others can connect it to their own backends.\n\nApache Shindig is the reference implementation of OpenSocial API specifications, versions 0.8.x and 0.9.x, a standard set of Social Network APIs.",
        "homepage": "http://shindig.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "javaee, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Sqoop",
        "description": "N/A",
        "homepage": "http://sqoop.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Stanbol",
        "description": "Apache Stanbol is a modular software stack and reusable set of components for semantic content management.",
        "homepage": "http://stanbol.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Stratos",
        "description": "Apache Stratos is a highly-extensible Platform-as-a-Service (PaaS) framework that helps run Apache Tomcat, PHP, and MySQL applications and can be extended to support many more environments on all major cloud infrastructures. For developers, Stratos provides a cloud-based environment for developing, testing, and running scalable applications. IT providers benefit from high utilization rates, automated resource management, and platform-wide insight including monitoring and billing.",
        "homepage": "http://stratos.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Submarine",
        "description": "Apache Submarine (Submarine for short) is an End-to-End Machine Learning Platform to allow data scientists to create end-to-end machine learning workflows. On Submarine, data scientists can finish each stage in the ML model lifecycle, including data exploration, data pipeline creation, model training, serving, and monitoring.",
        "homepage": "https://submarine.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, cloud, java, python, go",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tajo",
        "description": "\n      The main goal of Apache Tajo project is to build an advanced open\n      source data warehouse system in Hadoop for processing web-scale data\n      sets. Basically, Tajo provides SQL standard as a query language.\n      Tajo is designed for both interactive and batch queries on data sets\n      stored on HDFS and other data sources. Without hurting query response\n      times, Tajo provides fault-tolerance and dynamic load balancing which\n      are necessary for long-running queries. Tajo employs a cost-based and\n      progressive query optimization techniques for reoptimizing running\n      queries in order to avoid the worst query plans.\n    ",
        "homepage": "http://tajo.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tiles",
        "description": "Apache Tiles\u2122 is a templating framework built to simplify the development of web application user interfaces.\n\n    Tiles allows authors to define page fragments which can be assembled into a \n    complete page at runtime. These fragments, or tiles, can be used as simple \n    includes in order to reduce the duplication of common page elements or embedded \n    within other tiles to develop a series of reusable templates. These templates \n    streamline the development of a consistent look and feel across an entire application.\n    ",
        "homepage": "http://tiles.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Trafodion",
        "description": "Trafodion builds on the scalability, elasticity, and flexibility of Hadoop. Trafodion extends Hadoop to provide guaranteed transactional integrity, enabling new kinds of big data applications to run on Hadoop.",
        "homepage": "http://trafodion.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tuscany",
        "description": "Apache Tuscany simplifies the task of developing SOA solutions by providing a comprehensive infrastructure for SOA development and management that is based on Service Component Architecture (SCA) standard. With SCA as it's foundation, Tuscany offers solution developers the following advantages:\n\n    Provides a model for creating composite applications by defining the services in the fabric and their relationships with one another. The services can be implemented in any technology.\n    Enables service developers to create reusable services that only contain business logic. Protocols are pushed out of business logic and are handled through pluggable bindings. This lowers development cost.\n    Applications can easily adapt to infrastructure changes without recoding since protocols are handled via pluggable bindings and quality of services (transaction, security) are handled declaratively.\n    Existing applications can work with new SCA compositions. This allows for incremental growth towards a more flexible architecture, outsourcing or providing services to others.\n",
        "homepage": "http://tuscany.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache VXQuery",
        "description": "Apache VXQuery will be a standards compliant XML Query processor implemented in Java. The focus is on the evaluation of queries on large amounts of XML data. Specifically the goal is to evaluate queries on large collections of relatively small XML documents. To achieve this queries will be evaluated on a cluster of shared nothing machines.",
        "homepage": "http://vxquery.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "retired, big-data, xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Whirr",
        "description": "Apache Whirr is a set of libraries for running cloud services\n\nWhirr provides:\n1. A cloud-neutral way to run services. You don't have to worry about the idiosyncrasies of each provider.\n2. A common service API. The details of provisioning are particular to the service.\n3. Smart defaults for services. You can get a properly configured system running quickly, while still being able to override settings as needed.\n\nYou can also use Whirr as a command line tool for deploying clusters.",
        "homepage": "http://whirr.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Wink",
        "description": "Apache Wink is a simple yet solid framework for building RESTful Web services. It is comprised of a Server module and a Client module for developing and consuming RESTful Web services. ",
        "homepage": "http://wink.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "javaee, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Wookie",
        "description": "Apache Wookie is a Java server application that allows you to upload and deploy widgets for your applications; widgets can not only include all the usual kinds of mini-applications, badges, and gadgets, but also fully-collaborative applications such as chats, quizzes, and games.",
        "homepage": "http://wookie.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Xindice",
        "description": "Pure Java based native XML database. Supports XPath and XUpdate.",
        "homepage": "http://xml.apache.org/xindice/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml, retired",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Avro",
        "description": "Apache Avro is a data serialization system.",
        "homepage": "https://avro.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, big-data, data-engineering, integration",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Axis2",
        "description": "Apache Axis2 is a toolkit for creating and using Web Services, including SOAP, MTOM, XML/HTTP and advanced WS-* standards such as WSRM and WSSecurity.\n    Axis2 includes a very fast runtime engine, together with tooling support for WSDL and WS-Policy, and plugin support for WS-Addressing, WS-ReliableMessaging, WS-Security, \n    WS-Eventing, WS-Transactions, WS-Trust and WS-SecureConversation.\n    Axis2 runs either standalone or hosted in Tomcat or other servlet containers. \n    ",
        "homepage": "http://axis.apache.org/axis2/java/core",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml, http, network-server, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Sandesha2",
        "description": "Apache Sandesha2 is an Axis2 module that implements the WS-ReliableMessaging specification. It can be used both on the client side and on the server side.",
        "homepage": "http://axis.apache.org/axis2/java/sandesha/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Beam",
        "description": "Apache Beam is a unified programming model for both batch and streaming data processing, enabling efficient execution across diverse distributed execution engines and providing extensibility points for connecting to different technologies and user communities.",
        "homepage": "https://beam.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Bigtop",
        "description": "Bigtop is a project for the development of packaging and tests of the Apache Hadoop ecosystem. \n                 The primary goal of Bigtop is to build a community around the packaging and interoperability \n                 testing of Hadoop-related projects. This includes testing at various levels (packaging, platform, \n                 runtime, upgrade, etc...) developed by a community with a focus on the system as a whole, rather \n                 than individual projects. In short we strive to be for Hadoop what Debian is to Linux.",
        "homepage": "http://bigtop.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache BookKeeper",
        "description": "BookKeeper is a reliable replicated log service. It can be used to turn any standalone service into a highly available replicated service. BookKeeper is highly available (no single point of failure), and scales horizontally as more storage nodes are added.",
        "homepage": "http://bookkeeper.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Brooklyn",
        "description": "Brooklyn is about deploying and managing applications: composing a full stack for an application;\n        deploying to cloud and non-cloud targets; using monitoring tools to collect key health/performance metrics;\n        responding to situations such as a failing node; and adding or removing capacity to match demand.",
        "homepage": "http://brooklyn.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache bRPC",
        "description": "bRPC is an Industrial-grade RPC framework using C++ Language, which is often used in high performance system such as Search, Storage, Machine learning, Advertisement, Recommendation etc. \"bRPC\" means \"better RPC\".",
        "homepage": "https://brpc.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache BVal",
        "description": "The goal of the Apache BVal project is to deliver an implementation of the Java Bean Validation Specfication (JSR303/346) which is TCK compliant and works on Java SE 6 or later. The initial codebase for the project was donated to the ASF by a SGA from Agimatec GmbH and uses the Apache Software License v2.0.",
        "homepage": "http://bval.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "javaee, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Calcite",
        "description": "Calcite is a framework for writing data management\n      systems.  It converts queries, represented in relational algebra,\n      into an efficient executable form using pluggable query\n      transformation rules. There is an optional SQL parser and JDBC\n      driver. Calcite does not store data or have a preferred execution\n      engine. Data formats, execution algorithms, planning rules,\n      operator types, metadata, and cost model are added at runtime as\n      plugins.",
        "homepage": "https://calcite.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, hadoop, sql, geospatial",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Camel",
        "description": "Camel is an Open Source integration framework that empowers you to quickly and easily integrate various systems consuming or producing data",
        "homepage": "https://camel.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "integration, cloud, java, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache CarbonData",
        "description": "Apache CarbonData is a new big data file format for faster interactive query using advanced columnar storage, index, compression and encoding techniques to improve computing efficiency, which helps in speeding up queries by an order of magnitude faster over PetaBytes of data.",
        "homepage": "https://carbondata.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Cassandra",
        "description": "Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make Apache Cassandra the perfect platform for mission-critical data. Cassandra's support for replicating across multiple datacenters is best-in-class.\n\nCassandra is in use at Netflix, Twitter, Urban Airship, Constant Contact, Reddit, Cisco, OpenX, Digg, CloudKick, Ooyala, and more companies that have large, active data sets.\n\nCassandra provides full Hadoop integration, including with Pig and Hive.",
        "homepage": "http://cassandra.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Causeway",
        "description": "Apache Causeway is a framework for rapidly developing domain-driven apps in Java. Write your business logic in entities, domain services and repositories, and the framework dynamically (at runtime) generates a representation of that domain model as a webapp or as a RESTful API. For prototyping or production.",
        "homepage": "https://causeway.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Cayenne",
        "description": "Cayenne is a powerful, full-featured, opensource framework created for developers working with relational databases. it seamlessly maps any relational database to Java objects, reducing development time and adding considerable functionality to any application which requires a database. Developers using Cayenne will be able to concentrate on the core business requirements and the data model instead of the SQL details. The application can then be easily moved to any JDBC-capable database. In addition to management of persistent Java objects mapped to relational databases, Cayenne provides a plethora of features including single method call queries and updates (including atomic updates of all modified objects), seamless integration of multiple databases into a single virtual data source, three tier persistence with caching on the remote client, paging of results, record locking, and many more features.",
        "homepage": "https://cayenne.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, library, network-server, network-client, xml, web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Celix",
        "description": "\n      Apache Celix is a framework for C, C++14 and C++17 to develop dynamic modular software applications using component\n      and in-process service-oriented programming.\n      Apache Celix is inspired by the OSGi specification adapted for C and C++.\n    ",
        "homepage": "https://celix.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache CloudStack",
        "description": "Apache CloudStack is open source software designed to deploy and manage large \n        networks of virtual machines, as a highly available, highly scalable Infrastructure as \n        a Service (IaaS) cloud computing platform. CloudStack is used by a number of service \n        providers to offer public cloud services, and by many companies to provide an \n        on-premises (private) cloud offering, or as part of a hybrid cloud solution.\n        \n        CloudStack is a turnkey solution that includes the entire \"stack\" of features most \n        organizations want with an IaaS cloud: compute orchestration, Network-as-a-Service, \n        user and account management, a full and open native API, resource accounting, and a \n        first-class User Interface (UI).\n        \n        CloudStack currently supports the most popular hypervisors: VMware, KVM, XenServer and \n        Xen Cloud Platform (XCP).\n        \n        Users can manage their cloud with an easy to use Web interface, command line tools, and \n        / or a full-featured RESTful API. In addition, CloudStack provides an API that's \n        compatible with AWS EC2 and S3 for organizations that wish to deploy hybrid clouds.",
        "homepage": "http://cloudstack.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Cocoon",
        "description": "Apache Cocoon is a web development framework built around the concepts of separation of concerns (making sure people can interact and collaborate on a project, without stepping on each other toes) and component-based web development. Cocoon implements these concepts around the notion of \"component pipelines\", each component on the pipeline specializing on a particular operation. This makes it possible to use a \"building block\" approach for web solutions, hooking together components into pipelines without any required programming.",
        "homepage": "http://cocoon.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, graphics, http, network-client, network-server, web-framework, xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Community Development",
        "description": "N/A",
        "homepage": "https://community.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": [],
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons BCEL",
        "description": "\n      The Byte Code Engineering Library is intended to give users a convenient possibility to analyze, create, and manipulate (binary) Java class files (those ending with .class). Classes are represented by objects which contain all the symbolic information of the given class: methods, fields and byte code instructions, in particular.\n    ",
        "homepage": "http://commons.apache.org/bcel/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons BeanUtils",
        "description": "BeanUtils provides an easy-to-use but flexible wrapper around reflection and introspection.",
        "homepage": "https://commons.apache.org/beanutils/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons BSF",
        "description": "Bean Scripting Framework (BSF) is a set of Java classes which provides scripting language support within Java applications, and access to Java objects and methods from scripting languages. BSF allows one to write JSPs in languages other than Java while providing access to the Java class library. In addition, BSF permits any Java application to be implemented in part (or dynamically extended) by a language that is embedded within it. This is achieved by providing an API that permits calling scripting language engines from within Java, as well as an object registry that exposes Java objects to these scripting language engines.",
        "homepage": "http://commons.apache.org/bsf/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Chain (Dormant)",
        "description": "An implmentation of the GoF Chain of Responsibility pattern",
        "homepage": "http://commons.apache.org/chain/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons CLI",
        "description": "\n    Commons CLI provides a simple API for presenting, proecessing and\n    validating a command line interface.\n  ",
        "homepage": "http://commons.apache.org/cli/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Codec",
        "description": "\n   The codec package contains simple encoder and decoders for\n   various formats such as Base64 and Hexadecimal.  In addition to these\n   widely used encoders and decoders, the codec package also maintains a\n   collection of phonetic encoding utilities.\n  ",
        "homepage": "http://commons.apache.org/codec/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Collections",
        "description": "Types that extend and augment the Java Collections Framework.",
        "homepage": "http://commons.apache.org/collections/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Compress",
        "description": "Commons Compress: working with zip, ar, jar, bz2, cpio, tar, gz, dump, pack200, lzma, 7z, arj and xz files.",
        "homepage": "http://commons.apache.org/compress/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Configuration",
        "description": "\n      Library to use configuration/preferences of various sources and formats.\n    ",
        "homepage": "http://commons.apache.org/configuration/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Crypto",
        "description": "Commons Crypto: a cryptographic library optimized with AES-NI.",
        "homepage": "http://commons.apache.org/crypto/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons CSV",
        "description": "\n        The Apache Commons CSV library provides a simple interface for reading and writing\n        CSV files of various types.\n    ",
        "homepage": "http://commons.apache.org/csv/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Daemon",
        "description": "Commons Daemon",
        "homepage": "http://commons.apache.org/daemon/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons DBCP",
        "description": "Commons Database Connection Pooling",
        "homepage": "http://commons.apache.org/dbcp/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons DbUtils",
        "description": "A package of Java utility classes for easing JDBC development",
        "homepage": "http://commons.apache.org/dbutils/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Digester",
        "description": "\n    The Digester package lets you configure an XML->Java object mapping module\n    which triggers certain actions called rules whenever a particular\n    pattern of nested XML elements is recognized.\n  ",
        "homepage": "http://commons.apache.org/digester/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Email",
        "description": "\n      Commons-Email aims to provide a API for sending email.\n      It is built on top of the Java Mail API, which it aims to simplify.\n    ",
        "homepage": "http://commons.apache.org/email/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Exec",
        "description": "\n      A library to reliably execute external processes from within the JVM\n    ",
        "homepage": "http://commons.apache.org/exec/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons FileUpload",
        "description": "\n    The FileUpload component provides a simple yet flexible means of adding\n    support for multipart file upload functionality to servlets and web\n    applications.\n  ",
        "homepage": "http://commons.apache.org/fileupload/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Functor (Dormant)",
        "description": "The Apache Commons Functor library defines common functor and functor-related interfaces,\n    implementations, and utilities.",
        "homepage": "http://commons.apache.org/functor/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Geometry",
        "description": "Geometry.",
        "homepage": "http://commons.apache.org/geometry/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Imaging",
        "description": "\n      The Apache Commons Imaging library\n      reads and writes a variety of image formats,\n      including fast parsing of image info (size, color space, ICC profile, etc.) and metadata.\n      Previously known as Apache Commons Sanselan.\n    ",
        "homepage": "http://commons.apache.org/imaging/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons IO",
        "description": "\n        Commons-IO contains utility classes, stream implementations, file filters, file comparators and endian classes.\n  ",
        "homepage": "http://commons.apache.org/io/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons JCI",
        "description": "\n        Commons JCI provides a unified interface to any of several Java compilers.\n  ",
        "homepage": "http://commons.apache.org/jci/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons JCS",
        "description": "Comprehensive Caching System",
        "homepage": "http://commons.apache.org/jcs/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Jelly",
        "description": "Jelly is a Java and XML based scripting engine. Jelly combines the best ideas from JSTL, Velocity, DVSL, Ant and Cocoon all together in a simple yet powerful scripting engine.",
        "homepage": "http://commons.apache.org/jelly/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons JEXL",
        "description": "Jexl is an implementation of the JSTL Expression Language with extensions.",
        "homepage": "http://commons.apache.org/jexl/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons JXPath",
        "description": "A Java-based implementation of XPath 1.0 that, in addition to XML processing, can inspect/modify Java object graphs (the library's explicit purpose) and even mixed Java/XML structures.",
        "homepage": "http://commons.apache.org/jxpath/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Lang",
        "description": "\n        Commons Lang, a package of Java utility classes for the\n        classes that are in java.lang's hierarchy, or are considered to be so\n        standard as to justify existence in java.lang.\n    ",
        "homepage": "http://commons.apache.org/lang/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Logging",
        "description": "\n    Commons Logging is a thin adapter allowing configurable bridging to other,\n    well known logging systems.\n  ",
        "homepage": "http://commons.apache.org/logging/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Math",
        "description": "The Math project is a library of lightweight, self-contained mathematics and statistics components addressing the most common practical problems not immediately available in the Java programming language or commons-lang.",
        "homepage": "http://commons.apache.org/math/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Net",
        "description": "\n    Apache Commons Net library contains a collection of network utilities and protocol implementations.\n    Supported protocols include: Echo, Finger, FTP, NNTP, NTP, POP3(S), SMTP(S), Telnet, Whois\n    ",
        "homepage": "http://commons.apache.org/net/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Numbers",
        "description": "Number types and utilities.",
        "homepage": "http://commons.apache.org/numbers/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons OGNL (Dormant)",
        "description": "\n    The Apache Commons OGNL library is a Java development framework for Object-Graph Navigation Language,\n    plus other extras such as list projection and selection and lambda expressions.\n  ",
        "homepage": "http://commons.apache.org/ognl/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Pool",
        "description": "Commons Object Pooling Library",
        "homepage": "http://commons.apache.org/pool/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Proxy (Dormant)",
        "description": "Commons Dynamic Proxy Library",
        "homepage": "http://commons.apache.org/proxy/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons RDF",
        "description": "provide a type-safe, non-general API that covers RDF 1.1.",
        "homepage": "https://commons.apache.org/rdf/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons RNG",
        "description": "Implementations of pseudo-random generators.",
        "homepage": "https://commons.apache.org/rng/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons SCXML",
        "description": "\n     An implementation of the State Chart XML specification aimed at creating\n     and maintaining a Java SCXML engine. It is capable of executing an environment\n     agnostic state machine defined using a SCXML document.\n    ",
        "homepage": "http://commons.apache.org/scxml/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Statistics",
        "description": "Statistics.",
        "homepage": "http://commons.apache.org/statistics/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Text",
        "description": "\n        Apache Commons Text is a library focused on algorithms working on strings.\n    ",
        "homepage": "http://commons.apache.org/text/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Validator",
        "description": "\n    Commons Validator provides the building blocks for both client side validation\n    and server side data validation. It may be used standalone or with a framework like\n    Struts.\n  ",
        "homepage": "http://commons.apache.org/validator/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons VFS",
        "description": "\n        VFS is a Virtual File System library.\n    ",
        "homepage": "http://commons.apache.org/vfs/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons Weaver",
        "description": "\n      Apache Commons Weaver provides an easy way to enhance compiled Java\n      classes by generating (\"weaving\") bytecode into those classes.\n    ",
        "homepage": "http://commons.apache.org/weaver/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Cordova",
        "description": "Apache Cordova is a tool to create cross-platform apps from standard web technologies (HTML, CSS, and JavaScript). Its primary purpose is to provide a bridge for native device API access and to bundle for distribution.",
        "homepage": "https://cordova.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "mobile, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache CouchDB",
        "description": "Apache CouchDB is a database that completely embraces the web. Store your data with JSON documents. Access your documents with your web browser, via HTTP. Query, combine, and transform your documents with JavaScript. Apache CouchDB works well with modern web and mobile apps. CouchDB's killer feature is its ability to distribute data efficiently using Apache CouchDB\u2019s incremental replication. Apache CouchDB supports master-master setups with automatic conflict detection.",
        "homepage": "https://couchdb.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, http, network-client, network-server, cloud, content, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Rat",
        "description": "Apache Rat improves accuracy and efficiency when reviewing and auditing releases. \n    It is heuristic in nature: making guesses about possible problems. \n    It will produce false positives and cannot find every possible issue with a release. \n    It's reports require interpretation.\n\nApache Rat was developed in response to a need felt in the Apache Incubator to be able to \nreview releases for the most common faults less labour intensively. It is therefore highly tuned \nto the Apache style of releases.",
        "homepage": "http://creadur.apache.org/rat/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tentacles",
        "description": "Apache Tentacles helps the reviewer by automating interactions with the repository containing the artifacts comprising the release.",
        "homepage": "http://creadur.apache.org/tentacles",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Whisker",
        "description": "Apache Whisker allows an application to models the licensing characteristics of the contents of its distributions. Use cases are auditing the model against the contents of a distribution, reporting on the contents of a distribution and generation licensing documents (LICENSE, NOTICE and so on) for a distribution. Whisker distributes tooling for the command line and build system such as Maven.",
        "homepage": "http://creadur.apache.org/whisker",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache cTAKES",
        "description": "Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text. It processes clinical notes, identifying types of clinical named entities from various dictionaries including the Unified Medical Language System (UMLS) - medications, diseases/disorders, signs/symptoms, anatomical sites and procedures. Each named entity has attributes for the text span, the ontology mapping code, subject (patient, family member, etc.) and context (negated/not negated, conditional, generic, degree of certainty). Some of the attributes are expressed as relations, for example the location of a clinical condition (locationOf relation) or the severity of a clinical condition (degreeOf relation).",
        "homepage": "https://github.com/apache/ctakes",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Curator",
        "description": "Apache Curator is a Java/JVM client library for Apache ZooKeeper, a distributed coordination service. \n    It includes a highlevel API framework and utilities to make using Apache ZooKeeper much easier and more reliable. It also \n    includes recipes for common use cases and extensions such as service discovery and a Java 8 asynchronous DSL.",
        "homepage": "http://curator.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache CXF",
        "description": "Apache CXF is an open source services framework. CXF helps you build and develop services using frontend programming APIs like JAX-WS and JAX-RS. These services can speak a variety of protocols such as SOAP, XML/HTTP, RESTful HTTP, or CORBA and work over a variety of transports such as HTTP, JMS or JBI.",
        "homepage": "http://cxf.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, xml, network-client, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Daffodil",
        "description": "Apache Daffodil is an open-source implementation of\n        the DFDL specification that uses DFDL data descriptions to parse\n        fixed format data into an infoset. This infoset is commonly converted\n        into XML or JSON to enable the use of\n        well-established XML or JSON technologies and libraries to\n        consume, inspect, and manipulate fixed format data in existing\n        solutions. Daffodil is also capable of serializing or \"unparsing\"\n        data back to the original data format.\n        The DFDL infoset can also be converted directly to/from the \n        data structures carried by data processing frameworks so as to bypass any\n        XML/JSON overheads. ",
        "homepage": "https://daffodil.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, library, xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache DataFu",
        "description": "Apache DataFu consists of two libraries:\n\nApache DataFu Pig is a collection of useful user-defined functions for data analysis in Apache Pig.\n\nApache DataFu Hourglass is a library for incrementally processing data using Apache Hadoop MapReduce. This library was inspired by the prevelance of sliding window computations over daily tracking data. Computations such as these typically happen at regular intervals (e.g. daily, weekly), and therefore the sliding nature of the computations means that much of the work is unnecessarily repeated. DataFu's Hourglass was created to make these computations more efficient, yielding sometimes 50-95% reductions in computational resources.",
        "homepage": "http://datafu.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache DataFusion",
        "description": "\n        Apache DataFusion is a fast, extensible query engine for building high-quality data-centric systems\n        in Rust, using the Apache Arrow in-memory format. Python Bindings are also available. DataFusion offers SQL\n        and Dataframe APIs, excellent performance, built-in support for CSV, Parquet, JSON, and Avro,\n        extensive customization, and a great community.\n    ",
        "homepage": "https://datafusion.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database, data-engineering, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache datasketches",
        "description": "In the analysis of big data there are often problem queries that don\u2019t scale because they require huge compute resources and time to generate exact results. Examples include count distinct, quantiles, distribution analysis, most-frequent items, joins, matrix computations, and graph analysis.\n\nIf approximate results are acceptable, there is a class of specialized algorithms, called streaming algorithms, or sketches, that can produce results orders-of magnitude faster and with mathematically proven error bounds. For interactive queries there may not be other viable alternatives, and in the case of real-time analysis, sketches are the only known solution.",
        "homepage": "https://datasketches.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache  JDO",
        "description": "The POJO approach separates data manipulation (done by accessing Java data members in the Java domain objects) from database manipulation (done by calling the JDO interface methods). This separation of concerns leads to a high degree of independence of the Java view of data from the database view of the data.",
        "homepage": "https://db.apache.org/jdo/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Derby",
        "description": "Apache Derby is an open source relational database implemented entirely in Java. It has a small footprint that makes it easy to embed in any Java-based application, but it also supports the more familiar client/server mode. It is based on the Java, JDBC, and SQL standards, making code developed more portable to standards-compliant databases.",
        "homepage": "http://db.apache.org/derby",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Torque",
        "description": "Torque is an object-relational mapper for Java. In other words, Torque lets you access and manipulate data in a relational database using java objects. Unlike most other object-relational mappers, Torque does not use reflection to access user-provided classes, but it generates the necessary classes (including the Data Objects) from an XML schema describing the database layout (which can either be written by hand or generated from an existing database). The XML schema can also be used to generate and execute a SQL script which creates all the tables in the database.",
        "homepage": "http://db.apache.org/torque/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache DeltaSpike",
        "description": "Apache DeltaSpike is  a suite of portable CDI (Contexts & Dependency\nInjection) extensions intended to make application development easier when\nworking with CDI and Java EE.  Some of its key features include:\n\n- A core runtime that supports component configuration, type safe messaging\nand internationalization, and exception handling.\n- A suite of utilities to make programmatic bean lookup easier.\n- A plugin for Java SE to bootstrap both JBoss Weld and Apache OpenWebBeans\noutside of a container.\n- JSF integration, including backporting of JSF 2.2 features for Java EE 6.\n- JPA integration and transaction support.\n- A Data module, to create an easy to use repository pattern on top of JPA.\n- Quartz integration\n\nTesting support is also provided, to allow you to do low level unit testing\nof your CDI enabled projects.",
        "homepage": "http://deltaspike.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "javaee",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Directory",
        "description": "The Apache Directory project provides directory solutions entirely written in Java. These include a directory server, which has been certified as LDAP v3 compliant by the Open Group (ApacheDS), and Eclipse-based directory tools (Apache Directory Studio).",
        "homepage": "http://directory.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Fortress",
        "description": "Apache Fortress is a standards-based authorization system, written in Java, that provides role-based access control, delegated administration and password policy services using an LDAP backend.",
        "homepage": "https://directory.apache.org/fortress/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "identity-management, library, security, SDK",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Kerby",
        "description": "Apache Kerby is a Java Kerberos binding. It provides a rich, intuitive and interoperable implementation, library, KDC and various facilities that integrates PKI, OTP and token (OAuth2) as desired in modern environments such as cloud, Hadoop and mobile.",
        "homepage": "https://directory.apache.org/kerby/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "identity-management, identity-provisioning, Kerberos, library, security, SDK",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Directory Server",
        "description": "ApacheDS is an extensible and embeddable directory server entirely written in Java, which has been certified LDAPv3 compatible by the Open Group. Besides LDAP it supports Kerberos 5 and the Change Password Protocol. It has been designed to introduce triggers, stored procedures, queues and views to the world of LDAP which has lacked these rich constructs.",
        "homepage": "http://directory.apache.org/apacheds/1.5",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Directory Studio",
        "description": "Apache Directory Studio is a complete directory tooling platform intended to be used with any LDAP server however it is particularly designed for use with ApacheDS. It is an Eclipse RCP application, composed of several Eclipse (OSGi) plugins, that can be easily upgraded with additional ones. These plugins can even run within Eclipse itself.",
        "homepage": "http://directory.apache.org/studio/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Doris",
        "description": "Apache Doris is an easy-to-use, high-performance and real-time analytical database based on MPP architecture, known for its extreme speed and ease of use. It only requires a sub-second response time to return query results under massive data and can support not only high-concurrent point query scenarios but also high-throughput complex analysis scenarios.\n                 All this makes Apache Doris an ideal tool for scenarios including report analysis, ad-hoc query, unified data warehouse, and data lake query acceleration. On Apache Doris, users can build various applications, such as user behavior analysis, AB test platform, log retrieval analysis, user portrait analysis, and order analysis.",
        "homepage": "https://doris.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Drill",
        "description": "Apache Drill is a distributed MPP query layer that supports SQL and alternative query languages against NoSQL and Hadoop data storage systems. It was inspired in part by Google's Dremel.",
        "homepage": "http://drill.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Druid",
        "description": "Apache Druid is a high performance real-time analytics database. Druid's main value add is to reduce time to insight and action.\n\nApache Druid is designed for workflows where fast queries and ingest really matter. Druid excels at powering UIs, running operational (ad-hoc) queries, or handling high concurrency. Consider Druid as an open source alternative to data warehouses for a variety of use cases.",
        "homepage": "https://druid.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ECharts",
        "description": "Apache ECharts is a free, powerful charting and visualization library offering easy ways to add intuitive, interactive, and highly customizable charts to your commercial products. It is written in pure JavaScript and based on zrender, which is a whole new lightweight canvas library.",
        "homepage": "https://echarts.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, data-visualization",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Empire-db",
        "description": "\n\tApache Empire-db is intended for developers who strive to have full SQL freedom when \n\tformulating queries and DML-Statements - without ever having to use string literals -\n\tand who also want to be able to control when and how statements are executed. \n\n\tUnlike other approaches Empire-db does not rely on Java Annotations or Mapping-files\n\tfor building queries but rather uses a Java Object model that is easy to access and\n\textend. For Data Access and Data Interchange developers can choose between traditional \n\tJava Beans and a more sophisticated dynamic interface provided by Record and \n\tDataListEntriy classes.\n\n\tEmpire-db is DBMS vendor independent and provides handlers for Oracle, Microsoft SQLServer, \n\tPostgreSQL, MySQL, HsqlDB, Derby, H2 and more.\t\n\t",
        "homepage": "https://empire-db.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache EventMesh",
        "description": "EventMesh is a new generation serverless event middleware for building distributed event-driven applications.",
        "homepage": "https://eventmesh.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Felix",
        "description": "N/A",
        "homepage": "http://felix.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Fineract",
        "description": "At Apache Fineract, our mission is to build, maintain and enhance a cloud-ready core banking system for robust, scalable, and secure operations of financial institutions.",
        "homepage": "https://fineract.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": [],
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Flex",
        "description": "Apache Flex\u00ae is a highly productive, open source application framework for building and maintaining expressive web applications that deploy consistently on all major browsers, desktops and devices (including smartphones, tablets and tv). It provides a modern, standards-based language and programming model that supports common design patterns suitable for developers from many backgrounds. Flex applications can be deployed to the ubiquitous Adobe\u00ae Flash\u00ae Player in the browser, Adobe\u00ae AIR\u2122 on desktop and mobile or to native Android\u2122, IOS\u2122, QNX\u00ae, Windows\u00ae or Mac\u00ae applications.",
        "homepage": "http://flex.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Flink",
        "description": "Flink is an open source system for expressive, declarative, fast, and efficient data analysis. It combines the scalability and programming flexibility of distributed MapReduce-like platforms with the efficiency, out-of-core execution, and query optimization capabilities found in parallel databases.",
        "homepage": "http://flink.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Fluo",
        "description": "Apache Fluo is a distributed processing system that lets users\n      make incremental updates to large data sets. With Apache Fluo, users can\n      set up workflows that execute cross node transactions when data changes.\n      These workflows enable users to continuously join new data into large\n      existing data sets without reprocessing all data. Apache Fluo is built on\n      Apache Accumulo.",
        "homepage": "https://fluo.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Fluo Recipes",
        "description": "Apache Fluo Recipes build on the Fluo API to offer additional\n      functionality to developers. They are published separately from Fluo on\n      their own release schedule. This allows Fluo Recipes to iterate and\n      innovate faster than Fluo (which will maintain a more minimal API on a\n      slower release cycle). Fluo Recipes offers code to implement common\n      patterns on top of Fluo's API. It also offers glue code to external\n      libraries like Spark and Kryo.",
        "homepage": "https://fluo.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Fluo YARN",
        "description": "Apache Fluo YARN is a tool for running Apache Fluo\n      applications in Apache Hadoop YARN.",
        "homepage": "https://fluo.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache FreeMarker",
        "description": "\n          Apache FreeMarker is a template engine: a Java library to generate text output (HTML web pages, e-mails, configuration files, source code, etc.) based on templates and changing data.\n          Templates are written in the FreeMarker Template Language (FTL), which is a simple, specialized language (not a full-blown programming language).\n          Usually, a general-purpose programming language (like Java) is used to prepare the data (issue database queries, do business calculations). Then, Apache FreeMarker displays\n          that prepared data using templates. In the template you are focusing on how to present the data, and outside the template you are focusing on what data to present.\n    ",
        "homepage": "https://freemarker.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "Java, html, templating, content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Geode",
        "description": "Apache Geode is a data management platform that provides real-time, consistent access to data-intensive applications throughout widely distributed cloud architectures. Geode pools memory, CPU, network resources, and optionally local disk across multiple processes to manage application objects and behavior. It uses dynamic replication and data partitioning techniques to implement high availability, improved performance, scalability, and fault tolerance. In addition to being a distributed data container, Geode is an in-memory data management system that provides reliable asynchronous event notifications and guaranteed message delivery.",
        "homepage": "https://geode.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Geronimo",
        "description": "Apache Geronimo is an open source server runtime that integrates the best open source projects to create Java/OSGi server runtimes that meet the needs of enterprise developers and system administrators. Our most popular distribution is a fully certified Java EE 5 application server runtime.",
        "homepage": "http://geronimo.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "javaee, network-server, http, web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Gobblin",
        "description": "A distributed data integration framework that simplifies common aspects of big data integration such as data ingestion, replication, organization and lifecycle management for both streaming and batch data ecosystems.",
        "homepage": "https://gobblin.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Gora",
        "description": "Although there are various excellent ORM frameworks for relational databases, data modeling in NoSQL data stores differ profoundly from their relational cousins. Moreover, data-model agnostic frameworks such as JDO are not sufficient for use cases, where one needs to use the full power of the data models in column stores. Gora fills this gap by giving the user an easy-to-use in-memory data model and persistence for big data framework with data store specific mappings and built in Apache Hadoop support.",
        "homepage": "http://gora.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Groovy",
        "description": "Apache Groovy is a powerful, optionally typed and dynamic language, with static-typing and static compilation capabilities, for the Java platform aimed at improving developer productivity thanks to a concise, familiar and easy to learn syntax. It integrates smoothly with any Java program, and immediately delivers to your application powerful features, including scripting capabilities, Domain-Specific Language authoring, runtime and compile-time meta-programming and functional programming.",
        "homepage": "http://groovy.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Guacamole",
        "description": "Apache Guacamole is a clientless remote desktop gateway\n            which supports standard protocols like VNC, RDP, and SSH. We call\n            it \"clientless\" because no plugins or client software are required.\n            Once Guacamole is installed on a server, all you need to access\n            your desktops is a web browser.",
        "homepage": "http://guacamole.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-client, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Gump",
        "description": "N/A",
        "homepage": "http://gump.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management, testing",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Hadoop",
        "description": "The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.",
        "homepage": "https://hadoop.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache HBase",
        "description": "Use Apache HBase software when you need random, realtime read/write access to your Big Data. This project's goal is the hosting of very large tables -- billions of rows X millions of columns -- atop clusters of commodity hardware. HBase is an open-source, distributed, versioned, column-oriented store modeled after Google's Bigtable: A Distributed Storage System for Structured Data by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, HBase provides Bigtable-like capabilities on top of Hadoop and HDFS. ",
        "homepage": "https://hbase.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Helix",
        "description": "Apache Helix is a generic cluster management framework used for the automatic management of partitioned, replicated and distributed resources hosted on a cluster of nodes. Helix automates reassignment of resources in the face of node failure and recovery, cluster expansion, and reconfiguration.",
        "homepage": "http://helix.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud, big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Hive",
        "description": "The Apache Hive (TM) data warehouse software facilitates querying and managing large datasets residing in distributed storage. Built on top of Apache Hadoop (TM), it provides\n\n* tools to enable easy data extract/transform/load (ETL)\n* a mechanism to impose structure on a variety of data formats\n* access to files stored either directly in Apache HDFS (TM) or in other data storage systems such as Apache HBase (TM)\n* query execution via MapReduce\n\nHive defines a simple SQL-like query language, called HiveQL, that enables users familiar with SQL to query the data. At the same time, this language also allows programmers who are familiar with the MapReduce framework to be able to plug in their custom mappers and reducers to perform more sophisticated analysis that may not be supported by the built-in capabilities of the language. HiveQL can also be extended with custom scalar functions (UDF's), aggregations (UDAF's), and table functions (UDTF's).\n",
        "homepage": "http://hive.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Hop",
        "description": "The Hop Orchestration Platform, or Apache Hop, aims to facilitate all aspects of data and metadata orchestration.\n\nHop is an entirely new open source data integration platform that is easy to use, fast and flexible\n\nHop aims to be the future of data integration. Visual development enables developers to be more productive than they can be through code. Our Design once, run anywhere workflows and pipelines can be designed in the Hop Gui and run on the Hop native engine (local or remote), or on Spark, Flink, Google Dataflow or AWS EMR through Beam. Lifecycle Management enables developers and administrators to switch between projects, environments and purposes without leaving your train of thought.\n\n",
        "homepage": "https://hop.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache HttpComponents Client",
        "description": "\nHttpClient is a library for client-side HTTP communication built on HttpCore.\nIt provides connection management, cookie management, and authentication.\nThis is the successor to the widely used Jakarta Commons HttpClient 3.1.\n    ",
        "homepage": "http://hc.apache.org/httpcomponents-client/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "http, library, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Commons HttpClient",
        "description": "\nCommons HttpClient is a library for client-side HTTP communication.\nIt provides support for HTTP/1.1 and HTTP/1.0, plus\nvarious authentication schemes and cookie policies.\nThanks to it's widespread use and years of development, it is a very\nmature and stable codebase. However, due to limitations in the API design,\nCommons HttpClient will eventually be replaced by HttpClient 4.0\nwith a completely redesigned API based on HttpCore.\n    ",
        "homepage": "http://hc.apache.org/httpclient-3.x/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "http, library, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache HttpComponents Core",
        "description": "\n    HttpCore is a set of low level HTTP transport components that can be used to build custom\n    client and server side HTTP services with a minimal footprint. HttpCore supports two I/O\n    models: blocking I/O model based on the classic Java I/O and non-blocking, event driven I/O\n    model based on Java NIO.\n    ",
        "homepage": "http://hc.apache.org/httpcomponents-core/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "http, library, network-client, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache HTTP Server",
        "description": "\n      The Apache HTTP Server is an open-source HTTP server for modern\n      operating systems including UNIX, Microsoft Windows, Mac OS/X and Netware.\n      The goal of this project is to provide a secure, efficient and\n      extensible server that provides HTTP services observing the current\n      HTTP standards. Apache has been the most popular web server on the\n      Internet since April of 1996.\n    ",
        "homepage": "http://httpd.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, http, httpd-module",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache mod_ftp",
        "description": "\n      mod_ftp is an FTP Protocol module to serve httpd content over the FTP\n      protocol (whereever the HTTP protocol could also be used). It provides\n      both RETR/REST retrieval and STOR/APPE upload, using the same user/permissions\n      model as httpd (so it shares the same security considerations as mod_dav\n      plus mod_dav_fs). \n    ",
        "homepage": "http://httpd.apache.org/mod_ftp/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, ftp, httpd-module",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Hudi",
        "description": "Hudi (pronounced \u201cHoodie\u201d) brings stream processing to big data, providing upserts, deletes and incremental data streams.",
        "homepage": "https://hudi.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Iceberg",
        "description": "Iceberg brings the reliability and simplicity of SQL tables to big data, while making it possible for engines like Spark, Trino, Flink, Presto, Hive and Impala to safely work with the same tables, at the same time.",
        "homepage": "https://iceberg.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database, data-engineering",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Ignite",
        "description": "Apache Ignite is a distributed database for high-performance computing with in-memory speed.",
        "homepage": "http://ignite.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, sql, cloud, database, distributed-sql-database, data-management-platform, hadoop, network-server, network-client, osgi, iot",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Impala",
        "description": "Apache Impala is the open source, native analytic database for open data and table formats.",
        "homepage": "https://impala.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Annotator",
        "description": "Apache Annotator is a collaborative community for creating annotation related code which works to provide a future for Annotator.js-based projects and plugins while enabling W3C spec-compliant Web Annotation in Web browsers, Web Publication readers, and the servers that serve them.",
        "homepage": "http://annotator.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache InLong",
        "description": "Apache InLong is a one-stop, full-scenario integration framework for massive data that supports Data Ingestion, Data Synchronization, and Data Subscription, and it provides automatic, safe, reliable, and high-performance data transmission capabilities to facilitate the construction of streaming-based data analysis, modeling, and applications.",
        "homepage": "https://inlong.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache IoTDB",
        "description": "Apache IoTDB (Database for Internet of Things) is an integrated data management engine designed for time series data. It provides users with services for data collection, storage and analysis. Due to its light-weight architecture, high performance and rich feature set together with its deep integration with Apache Hadoop, Spark and Flink. Apache IoTDB can meet the requirements of massive data storage, high-speed data ingestion and complex data analysis in the IoT industrial fields.",
        "homepage": "http://iotdb.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, iot, java, python, c++, go, csharp",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Jackrabbit",
        "description": "\n      Apache Jackrabbit is a fully conforming implementation of the\n      Content Repository for Java Technology API (JCR). A content\n      repository is a hierarchical content store with support for\n      structured and unstructured content, full text search, versioning,\n      transactions, observation, and more. Typical applications that use\n      content repositories include content management, document management,\n      and records management systems.\n    ",
        "homepage": "http://jackrabbit.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, library, network-server, xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache JAMES",
        "description": "The Apache Java Enterprise Mail Server (a.k.a. Apache James) is a 100% pure Java SMTP and POP3 Mail server and NNTP News server. We have designed James to be a complete and portable enterprise mail engine solution based on currently available open protocols.\n\nJames is also a mail application platform. We have developed a Java API to let you write Java code to process emails that we call the mailet API. A mailet can generate an automatic reply, update a database, prevent spam, build a message archive, or whatever you can imagine. A matcher determines whether your mailet should process an email in the server. The James project hosts the Mailet API, and James provides an implementation of this mail application platform API.\n",
        "homepage": "http://james.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "mail, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache jclouds",
        "description": "Apache jclouds is an open source multi-cloud toolkit for the Java platform that gives you the freedom to create applications that are portable across clouds while giving you full control to use cloud-specific features.",
        "homepage": "http://jclouds.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Jena",
        "description": "Apache Jena provides a complete framework for building Semantic Web and Linked Data applications in Java, and provides: parsers for RDF/XML, Turtle and N-triples; a Java programming API; a complete implementation of the SPARQL query language; a rule-based inference engine for RDFS and OWL entailments; TDB (a non-SQL persistent triple store); SDB (a persistent triples store built on a relational store) and Fuseki, an RDF server using web protocols. Jena complies with all relevant recommendations for RDF and related technologies from the W3C.",
        "homepage": "http://jena.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache JMeter",
        "description": "Apache JMeter may be used to test performance both on static and dynamic resources (files, Servlets, Perl scripts, Java Objects, Data Bases and Queries, FTP Servers and more). It can be used to simulate a heavy load on a server, network or object to test its strength or to analyze overall performance under different load types. You can use it to make a graphical analysis of performance or to test your server/script/object behavior under heavy concurrent load. ",
        "homepage": "http://jmeter.apache.org/index.html",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "testing",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache JSPWiki",
        "description": "\n        Apache JSPWiki is a feature-rich and extensible WikiWiki engine built around the standard JEE \n        components (Java, servlets, JSP). It features:\n        - WikiMarkup/Structured Text\n        - File attachments \n        - Templates support\n        - Data storage through 2 WikiPage Providers, with the capability to plug new ones\n        - Security: Authorization and authentication fine grain control\n        - Easy plugin and page filter interfaces\n        - UTF-8 support\n        - JSP-based\n        - Easy-ish installation\n        - Page locking to prevent editing conflicts\n        - Support for Multiple Wikis\n        - Custom User Preferences\n    ",
        "homepage": "http://jspwiki.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Kafka",
        "description": "A single Kafka broker can handle hundreds of megabytes of reads and writes per second from thousands of clients. Kafka is designed to allow a single cluster to serve as the central data backbone for a large organization. It can be elastically and transparently expanded without downtime. Data streams are partitioned and spread over a cluster of machines to allow data streams larger than the capability of any single machine and to allow clusters of co-ordinated consumers. Kafka has a modern cluster-centric design that offers strong durability and fault-tolerance guarantees. Messages are persisted on disk and replicated within the cluster to prevent data loss. Each broker can handle terabytes of messages without performance impact.",
        "homepage": "https://kafka.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Karaf",
        "description": "Apache Karaf is a small OSGi based runtime which provides a lightweight container onto which various components and applications can be deployed.",
        "homepage": "http://karaf.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, osgi",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Kibble",
        "description": "Apache Kibble is a suite of tools for collecting, aggregating and visualizing activity in software projects. ",
        "homepage": "https://kibble.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Knox",
        "description": "The Apache Knox Gateway is a REST API Gateway for interacting with Hadoop clusters.\n\nThe Knox Gateway provides a single access point for all REST interactions with Hadoop clusters.\n\nIn this capacity, the Knox Gateway is able to provide valuable functionality to aid in the control,\nintegration, monitoring and automation of critical administrative and analytical needs of the enterprise.\n\nAuthentication (LDAP and Active Directory Authentication Provider)\nFederation/SSO (HTTP Header Based Identity Federation)\nAuthorization (Service Level Authorization)\nAuditing\nWhile there are a number of benefits for unsecured Hadoop clusters,\nthe Knox Gateway also complements the kerberos secured cluster quite nicely.\n\nCoupled with proper network isolation of a Kerberos secured Hadoop cluster,\nthe Knox Gateway provides the enterprise with a solution that:\n\nIntegrates well with enterprise identity management solutions\nProtects the details of the Hadoop cluster deployment (hosts and ports are hidden from endusers)\nSimplifies the number of services that clients need to interact with",
        "homepage": "https://knox.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Kudu",
        "description": "Apache Kudu is a columnar storage manager developed for the Apache Hadoop platform.",
        "homepage": "https://kudu.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Kylin",
        "description": "Apache Kylin is an open source, distributed Analytical Data Warehouse for Big Data; it was designed to provide OLAP (Online Analytical Processing) capability in the big data era. By renovating the multi-dimensional cube and precalculation technology on Hadoop and Spark, Kylin is able to achieve near constant query speed regardless of the ever-growing data volume. Reducing query latency from minutes to sub-second, Kylin brings online analytics back to big data.",
        "homepage": "https://kylin.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Libcloud",
        "description": "Apache Libcloud is a standard Python library that abstracts away differences among multiple cloud provider APIs. It allows users to manage cloud servers, cloud storage and load-balancers.",
        "homepage": "http://libcloud.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Linkis",
        "description": "Apache Linkis is a computation middleware project, which decouples the upper applications and the underlying data engines, provides standardized interfaces (REST, JDBC etc.) to easily connect to various underlying engines (Spark, Presto, Flink, etc.).",
        "homepage": "https://linkis.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Chainsaw",
        "description": "N/A",
        "homepage": "http://logging.apache.org/log4j/docs/chainsaw.html",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Flume",
        "description": "Apache Flume is a distributed, reliable, and available system for efficiently collecting, aggregating and moving large amounts of log data from many different sources to a centralized data store",
        "homepage": "http://flume.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache log4cxx",
        "description": "N/A",
        "homepage": "https://logging.apache.org/log4cxx",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Log4j",
        "description": "N/A",
        "homepage": "https://logging.apache.org/log4j",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache log4net",
        "description": "N/A",
        "homepage": "http://logging.apache.org/log4net/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache log4php",
        "description": "N/A",
        "homepage": "http://logging.apache.org/log4php/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Lucene Core",
        "description": "Apache Lucene is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search, especially cross-platform.\n    ",
        "homepage": "https://lucene.apache.org/core/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, library, search",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache PyLucene",
        "description": "PyLucene is a Python extension for accessing Java Lucene TM. Its goal is to allow you to use Lucene's text indexing and searching capabilities from Python.",
        "homepage": "https://lucene.apache.org/pylucene/index.html",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "search, library, python, c++",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Lucene.Net",
        "description": "Lucene.Net is a port of the Lucene search engine library, written in C# and targeted at .NET runtime users. The Lucene search library is based on an inverted index. Lucene.Net has three primary goals:\n\n1. Maintain the existing line-by-line port from Java to C#, fully automating and commoditizing the process such that the project can easily synchronize with the Java Lucene release schedule;\n2. Maintaining the high-performance requirements expected of a first class C# search engine library;\n3. Maximize usability and power when used within the .NET runtime. To that end, it will present a highly idiomatic, carefully tailored API that takes advantage of many of the special features of the .NET runtime.\n",
        "homepage": "http://lucenenet.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Mahout",
        "description": "N/A",
        "homepage": "http://mahout.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ManifoldCF",
        "description": "ManifoldCF is an effort to provide an open source framework for connecting source content repositories like Microsoft Sharepoint and EMC Documentum, to target repositories or indexes, such as Apache Solr , OpenSearchServer or ElasticSearch. ManifoldCF also defines a security model for target repositories that permits them to enforce source-repository security policies.",
        "homepage": "http://manifoldcf.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Maven",
        "description": "Maven is a project development management and comprehension tool. Based on the concept of a project object model: builds, dependency management, documentation creation, site publication, and distribution publication are all controlled from the declarative file. Maven can be extended by plugins to utilise a number of other development tools for reporting or the build process.",
        "homepage": "https://maven.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Maven Doxia",
        "description": "Doxia is a content generation framework which aims to provide its users with powerful techniques for generating static and dynamic content: Doxia can be used in web-based publishing context to generate static sites, in addition to being incorporated into dynamic content generation systems like blogs, wikis and content management systems.",
        "homepage": "https://maven.apache.org/doxia/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Mesos",
        "description": "Apache Mesos is a cluster manager that provides efficient resource isolation \nand sharing across distributed applications, or frameworks. It can run Hadoop, \nMPI, Hypertable, Spark, and other frameworks on a dynamically shared pool of \nnodes.\n",
        "homepage": "http://mesos.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache MINA",
        "description": "Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. It provides an abstract, event-driven, asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.",
        "homepage": "http://mina.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-client, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache FtpServer",
        "description": "The Apache FtpServer application is a 100% pure Java FTP server. It's designed to be a complete and portable FTP server engine solution based on currently available open protocols. FtpServer can be run standalone as a Windows service or Unix/Linux daemon, or embedded into a Java application. We also provide support for integration within Spring applications and provide our releases as OSGi bundles.",
        "homepage": "http://mina.apache.org/ftpserver-project",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache SSHD",
        "description": "Apache SSHD is a 100% pure java library to support the SSH protocols on both the client and server side. This library is based on Apache MINA, a scalable and high performance asynchronous IO library. SSHD does not really aim at being a replacement for the SSH client or SSH server from Unix operating systems, but rather provides support for Java based applications requiring SSH support.",
        "homepage": "http://mina.apache.org/sshd-project",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Vysper",
        "description": "Apache Vysper aims to be a modular, full featured XMPP (Jabber) server. Vysper is implemented in Java.",
        "homepage": "http://mina.apache.org/vysper-project",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache MyFaces",
        "description": "MyFaces is the free open source implementation of Jakarta Server Faces, a web application framework that accomplishes the MVC paradigm. It is comparable to the well-known Struts Framework but has features and concepts that are beyond those of Struts - especially the component orientation.",
        "homepage": "http://myfaces.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, javaee",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tobago",
        "description": "The goal of Tobago is to provide the community with a well designed set of user interface components based on JSF.",
        "homepage": "http://myfaces.apache.org/#/tobago",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Mynewt",
        "description": "Apache Mynewt is a community-driven module OS for constrained, embedded applications. Mynewt provides a real-time operating system, flash file system, network stacks, and support utilities for real-world embedded systems. Its goal is to make it easy to develop applications for microcontroller environments where power and cost are driving factors.",
        "homepage": "https://mynewt.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "iot",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache NetBeans",
        "description": "Apache NetBeans is and IDE for many language (java, php, ...). Apache NetBeans is a platform that can be extended by third party developer.",
        "homepage": "https://netbeans.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "java, groovy, php, ide",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache NiFi",
        "description": "The mission of NiFi is the creation and maintenance of software related to providing an easy to use, powerful, and reliable system to process and distribute data.\n\nApache NiFi MiNiFi is an edge data collection agent built to seamlessly integrate with and leverage the command and control of NiFi. There are both Java and C++ implementations.\n\nApache NiFi Registry is a centralized registry for key configuration items including flow versions, assets, and extensions for Apache NiFi and Apache MiNiFi.",
        "homepage": "https://nifi.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Nutch",
        "description": "Apache Nutch is a highly extensible and scalable open source web crawler software project. Stemming from Apache Lucene, Nutch is a well matured, production ready batch crawler relying on Apache Hadoop data structures, which are great for batch processing. Nutch has a modular architecture and provides pluggable and extensible interfaces such as Parse, Index and ScoringFilter's for custom implementations e.g. Apache Tika for parsing. Additionally, pluggable indexers exists for Apache Solr, Elastic Search, etc. Nutch can run on a single machine, but gains a lot of its strength from running in a Hadoop cluster. The now retired branch Nutch 2.x differed from 1.x in one key area: storage is abstracted away from any specific underlying data store by using Apache Gora for handling object to persistent mappings and to store fetch time, status, content, parsed text, outlinks, inlinks, etc. into a number of NoSQL storage solutions.",
        "homepage": "https://nutch.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OFBiz",
        "description": "\n      Apache OFBiz is an open source product for the automation of enterprise processes that includes framework components and business applications\n      for ERP (Enterprise Resource Planning), CRM (Customer Relationship Management), E-Business / E-Commerce, SCM (Supply Chain Management),\n      MRP (Manufacturing Resource Planning), MMS/EAM (Maintenance Management System/Enterprise Asset Management).\n      Apache OFBiz provides a foundation and starting point for reliable, secure and scalable enterprise solutions, see https://ofbiz.apache.org/ for more.\n    ",
        "homepage": "http://ofbiz.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, database, network-server, xml, http, content, geospatial",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Olingo",
        "description": "Apache Olingo is a Java library that implements the Open Data Protocol (OData). Apache Olingo serves client and server aspects of OData. It currently supports OData 2.0 and support OData 4.0 (beta). The latter is the OASIS version of the protocol: OASIS Open Data Protocol (OData) TC.\n\nThe extensions part of Olingo for OData 2.0 contains additional features like the support of JPA persistency or annotated bean classes.\n    ",
        "homepage": "http://olingo.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Oozie",
        "description": "Oozie is a workflow scheduler system to manage Apache Hadoop jobs. Oozie is integrated with the rest of the Hadoop stack supporting several types of Hadoop jobs out of the box (such as Java map-reduce, Streaming map-reduce, Pig, Hive, Sqoop and Distcp) as well as system specific jobs (such as Java programs and shell scripts).",
        "homepage": "http://oozie.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OpenDAL",
        "description": "Apache OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way.",
        "homepage": "https://opendal.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "data-engineering",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OpenJPA",
        "description": "Apache OpenJPA is a Java persistence project at The Apache Software Foundation that can be used as a stand-alone POJO persistence layer or integrated into any Java EE compliant container and many other lightweight frameworks, such as Tomcat and Spring.  The 1.x releases are a production ready, feature-rich, compliant implementation of the Java Persistence API (JPA) 1.0 part of the JSR-220 Enterprise Java Beans 3.0 specification, which pass the Sun JPA 1.0b Technology Compatibility Kit.  The 2.x releases are a production ready, compliant implement of the JSR-317 Java Persistence 2.0 specification, which is backwards compatible to the JPA 1.0 specification and passes the Sun JPA 2.0 Technology Compatibility Kit.",
        "homepage": "http://openjpa.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database, library, javaee",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OpenMeetings",
        "description": "\n      The Apache OpenMeetings provides video conferencing, instant messaging, white board, \n      collaborative document editing and other groupware tools using API functions \n      of the Red5 Streaming Server for Remoting and Streaming.\n    ",
        "homepage": "https://openmeetings.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OpenNLP",
        "description": "Apache OpenNLP software supports the most common NLP tasks, such as tokenization, sentence segmentation, part-of-speech tagging, named entity extraction, chunking, parsing, and coreference resolution. These tasks are usually required to build more advanced text processing services. OpenNLP also includes maximum entropy and perceptron based machine learning.",
        "homepage": "http://opennlp.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OpenOffice",
        "description": "Apache OpenOffice is a leading open-source, office-document\n      productivity suite providing six productivity applications (Writer, Calc,\n      Impress, Draw, Math, Base) based around the OpenDocument Format (ODF).\n      OpenOffice is released on Windows, macOS (OS X), Linux 32-bit DEB+RPM,\n      Linux 64-bit DEB+RPM and in 41languages.\n    ",
        "homepage": "https://openoffice.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache OpenWebBeans",
        "description": "OpenWebBeans is an ALv2-licensed implementation of the \"Contexts and Dependency Injection for the Java EE platform\" specification which is defined as JSR-299.",
        "homepage": "http://openwebbeans.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "javaee",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ORC",
        "description": "ORC is a self-describing type-aware columnar file format designed for\nHadoop workloads. It is optimized for large streaming reads, but with\nintegrated support for finding required rows quickly. Storing data in\na columnar format lets the reader read, decompress, and process only\nthe values that are required for the current query.",
        "homepage": "https://orc.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database, hadoop, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Ozone",
        "description": "Apache Ozone is a highly scalable, distributed storage for Analytics, Big data and Cloud Native applications. Ozone supports S3 compatible object APIs as well as a Hadoop Compatible File System implementation. It is optimized for both efficient object store and file system operations.\nIt is built on a highly available, replicated block storage layer called Hadoop Distributed Data Store (HDDS).\nApplications using frameworks like Apache Spark, YARN and Hive work natively without any modifications. ",
        "homepage": "https://ozone.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Parquet",
        "description": "Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval. It provides high performance compression and encoding schemes to handle complex data in bulk and is supported in many programming language and analytics tools.",
        "homepage": "http://parquet.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache PDFBox",
        "description": "N/A",
        "homepage": "https://pdfbox.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache mod_perl",
        "description": "\nmod_perl is a unique piece of software that integrates the power of\nPerl with the flexibility and stability of the Apache Web server.\nWith mod_perl, you can harness the power of the full Apache API with\nPerl and develop Web applications quickly, without sacrificing\nperformance.\n    ",
        "homepage": "http://perl.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "httpd-module",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Petri",
        "description": "Apache Petri deals with the assessment of, education in, and adoption of the Foundation's policies and procedures for collaborative development and the pros and cons of joining the Foundation.",
        "homepage": "http://petri.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "education",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Phoenix",
        "description": "Apache Phoenix enables OLTP and operational analytics for Apache Hadoop by providing a relational database layer leveraging Apache HBase as its backing store. It includes integration with Apache Spark, Pig, Flume, Map Reduce, and other products in the Hadoop ecosystem. It is accessed as a JDBC driver and enables querying, updating, and managing HBase tables through standard SQL.",
        "homepage": "http://phoenix.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Pig",
        "description": "Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. The salient property of Pig programs is that their structure is amenable to substantial parallelization, which in turns enables them to handle very large data sets.\n\nPig's infrastructure layer consists of a compiler that produces sequences of Map-Reduce programs. Pig's language layer consists of a textual language called Pig Latin, which has the following key properties:\n\n* Ease of programming. It is trivial to achieve parallel execution of simple, \"embarrassingly parallel\" data analysis tasks. Complex tasks comprised of multiple interrelated data transformations are explicitly encoded as data flow sequences, making them easy to write, understand, and maintain.\n * Optimization opportunities. The way in which tasks are encoded permits the system to optimize their execution automatically, allowing the user to focus on semantics rather than efficiency.\n * Extensibility. Users can create their own functions to do special-purpose processing.\n",
        "homepage": "http://pig.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Pinot",
        "description": "Apache Pinot is a real-time distributed online analytical processing (OLAP) datastore. Use Pinot to ingest and immediately query data from streaming or batch data sources (including, Apache Kafka, Amazon Kinesis, Hadoop HDFS, Amazon S3, Azure ADLS, and Google Cloud Storage).\nApache Pinot includes the following:\nUltra low-latency analytics even at extremely high throughput.\nColumnar data store with several smart indexing and pre-aggregation techniques.\nScaling up and out with no upper bound.\nConsistent performance based on the size of your cluster and an expected query per second (QPS) threshold.\nIt's perfect for user-facing real-time analytics and other analytical use cases, including internal dashboards, anomaly detection, and ad hoc data exploration.",
        "homepage": "https://pinot.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Pivot",
        "description": "Apache Pivot is an open-source platform for building installable Internet applications (IIAs).\nIt combines the enhanced productivity and usability features of a modern user interface toolkit with the robustness of the Java platform.\n",
        "homepage": "http://pivot.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache PLC4X",
        "description": "PLC4X is a set of libraries for communicating with industrial programmable logic controllers (PLCs) using a variety of protocols but with a shared API.",
        "homepage": "https://plc4x.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "c, c++, go, integration, iot, java, library, network-client, python",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache POI",
        "description": "APIs for manipulating various file formats based upon Open Office XML (ECMA-376) and Microsoft's OLE 2 Compound Document formats using pure Java. Apache POI is your Java Excel, Word and PowerPoint solution. We have a complete API for porting other OOXML and OLE 2 Compound Document formats and welcome others to participate.",
        "homepage": "https://poi.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache XMLBeans",
        "description": "XMLBeans is a tool that allows you to access the full power of XML in a Java friendly way. The idea\n            is that you can take advantage of the richness and features of XML and XML Schema and have these features\n            mapped as naturally as possible to the equivalent Java language and typing constructs. XMLBeans uses XML\n            Schema to compile Java interfaces and classes that you can then use to access and modify XML instance data.\n            Using XMLBeans is similar to using any other Java interface/class, you will see things like getFoo or setFoo\n            just as you would expect when working with Java. While a major use of XMLBeans is to access your XML\n            instance data with strongly typed Java classes there are also API's that allow you access to the full XML\n            infoset (XMLBeans keeps XML Infoset fidelity) as well as to allow you to reflect into the XML schema itself\n            through an XML Schema Object model.\n\n            For more details on XMLBeans see the XMLBeans Wiki pages or the XMLBeans documentation (the Documentation\n            tab on this website).\n            What Makes XMLBeans Different\n\n            There are at least two major things that make XMLBeans unique from other XML-Java binding options.\n\n            1. Full XML Schema support. XMLBeans fully supports XML Schema and the corresponding java classes provide\n            constructs for all of the major functionality of XML Schema. This is critical since often times you do not\n            have control over the features of XML Schema that you need to work with in Java. Also, XML Schema oriented\n            applications can take full advantage of the power of XML Schema and not have to restrict themselvs to a\n            subset.\n            2. Full XML Infoset fidelity.When unmarshalling an XML instance the full XML infoset is kept and is\n            available to the developer. This is critical because because of the subset of XML that is not easily\n            represented in java. For example, order of the elements or comments might be needed in a particular\n            application.\n\n            A major objective of XMLBeans has been to be applicable in all non-streaming (in memory) XML programming\n            situations. You should be able to compile your XML Schema into a set of java classes and know that 1) you\n            will be able to use XMLBeans for all of the schemas you encounter (even the warped ones) and 2) that you\n            will be able to get to the XML at whatever level is necessary - and not have to resort to multple tools to\n            do this.\n\n            To accomplish this XMLBeans provides three major APIs:\n\n            * XmlObject The java classes that are generated from an XML Schema are all derived from XmlObject. These\n            provide strongly typed getters and setters for each of the elements within the defined XML. Complex types\n            are in turn XmlObjects. For example getCustomer might return a CustomerType (which is an XmlObject). Simple\n            types turn into simple getters and setters with the correct java type. For example getName might return a\n            String.\n            * XmlCursor From any XmlObject you can get an XmlCursor. This provides efficient, low level access to the\n            XML Infoset. A cursor represents a position in the XML instance. You can move the cursor around the XML\n            instance at any level of granularity you need from individual characters to Tokens.\n            * SchemaType XMLBeans provides a full XML Schema object model that you can use to reflect on the underlying\n            schema meta information. For example, you might want to generate a sample XML instance for an XML schema or\n            perhaps find the enumerations for an element so that you can display them.\n\n            All of this was built with performance in mind. Informal benchmarks and user feedback indicate that XMLBeans\n            is extremely fast.\n        ",
        "homepage": "https://xmlbeans.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Portals",
        "description": "The Apache Portals project provides various software products, including Apache Jetspeed-2, Apache Pluto, and Apache Portals Applications.",
        "homepage": "http://portals.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Pulsar",
        "description": "Apache Pulsar is an all-in-one messaging and streaming platform. Messages can be consumed and acknowledged individually or consumed as streams with less than 10ms of latency. Its layered architecture allows rapid scaling across hundreds of nodes, without data reshuffling.\n\nIts features include multi-tenancy with resource separation and access control, geo-replication across regions, tiered storage and support for six official client languages. It supports up to one million unique topics and is designed to simplify your application architecture.",
        "homepage": "https://pulsar.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Qpid",
        "description": "Apache Qpid implements the latest AMQP specification, the first open standard for enterprise messaging, and provides transaction management, queuing, distribution, security, management, clustering, federation and heterogeneous multi-platform support and a lot more.",
        "homepage": "http://qpid.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Ranger",
        "description": "Apache Ranger is a framework to enable, monitor and manage comprehensive data security - consistently across various data processing services. Integrated with most of the Big-Data technologies (Hadoop, Hive, HBase, Spark, Trino, ...)",
        "homepage": "https://ranger.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, security",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Roller",
        "description": "Apache Roller is a full-featured, multi-user and group-blog server suitable for blog sites large and small. It runs as a Java web application that should be able to run on most any Java EE server and relational database. Roller's installation guide covers deployment on Tomcat, GlassFish, and JBoss application servers using a MySQL, Derby, or PostgreSQL database. Users however have reported success running Roller on other app servers and databases.\n\n            -    Multi-user blogging: can support tens of thousands of users and blogs\n            -    Group blogging with three permisson levels (editor, author and limited)\n            -    Support for comment moderation and comment spam prevention measures\n            -    Bloggers have complete control over blog layout/style via Apache Velocity-driven templates\n            -    Built-in search engine indexes weblog entry content\n            -    Pluggable cache and rendering system\n            -    Support for blog clients that support MetaWeblog API\n            -    All blogs have entry and comment feeds in both RSS 2.0 and Atom 1.0 formats",
        "homepage": "http://roller.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Royale",
        "description": "Apache Royale implements the principles of Apache Flex to support development of applications designed for JavaScript instead of Adobe Flash/AIR runtimes. Apache Royale improves developer productivity in creating applications to run wherever JavaScript runs, including on browsers, in Apache Cordova applications, on Node, and on other platforms.",
        "homepage": "https://royale.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Samza",
        "description": "Apache Samza provides a system for processing stream data from publish-subscribe systems such as Apache Kafka. The developer writes a stream processing task, and executes it as a Samza job. Samza then routes messages between stream processing tasks and the publish-subscribe systems that the messages are addressed to.",
        "homepage": "http://samza.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Santuario",
        "description": "N/A",
        "homepage": "http://santuario.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, security, xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache SeaTunnel",
        "description": "SeaTunnel is a next-generation super high-performance, distributed, massive data integration tool. It can synchronize tens of billions of data stably and efficiently every day, and has been used in the production of many companies.",
        "homepage": "https://seatunnel.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Serf",
        "description": "The serf library is a high performance C-based HTTP client library built upon the Apache Portable Runtime (APR) library",
        "homepage": "http://serf.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ServiceMix",
        "description": "Apache ServiceMix is a flexible, open-source integration container that unifies the features and functionality of Apache ActiveMQ, Camel, CXF, and Karaf into a powerful runtime platform you can use to build your own integrations solutions. It provides a complete, enterprise ready ESB exclusively powered by OSGi.",
        "homepage": "http://servicemix.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-client, network-server, xml, osgi",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Shiro",
        "description": "Apache Shiro is a powerful and flexible open-source security framework that cleanly handles\n        authentication, authorization, enterprise session management, single sign-on and cryptography services.",
        "homepage": "https://shiro.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Spatial Information System",
        "description": "Apache SIS provides data structures for geographic data and associated metadata\n        along with methods to manipulate those data structures. The library is an implementation of GeoAPI interfaces\n        and can be used for desktop or server applications.",
        "homepage": "http://sis.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "geospatial, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache SkyWalking",
        "description": "Use Apache SkyWalking when you need an application performance monitor tool for distributed systems, especially designed for microservices, cloud native and container-based (Docker, K8s, Mesos) architectures.",
        "homepage": "http://skywalking.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "observability",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Sling",
        "description": "\n        Apache Sling is a web framework that uses a Java Content Repository, such as Apache Jackrabbit, \n        to store and manage content.\n        Sling applications use either scripts or Java servlets, selected based on simple name conventions, \n        to process HTTP requests in a RESTful way.\n        The embedded Apache Felix OSGi framework and console provide a dynamic runtime environment, where \n        code and content bundles can be loaded, unloaded and reconfigured at runtime.\n        As the first web framework dedicated to JSR-170 Java Content Repositories, Sling makes it very \n        simple to implement simple applications, while providing an enterprise-level framework for more complex applications.\n    ",
        "homepage": "http://sling.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": [],
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Solr",
        "description": "Solr is an open source enterprise search server based on the Lucene Java search library, with Rest-like JSON/HTTP APIs, high performance, high availability, powerful analytics, hit highlighting, faceted search, caching, replication, and a web administration interface.\n    ",
        "homepage": "http://solr.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, network-server, search, java",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Solr Operator",
        "description": "N/A",
        "homepage": "https://solr.apache.org/operator",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud, search, go",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache SpamAssassin",
        "description": "Apache SpamAssassin is an extensible email filter which is used to identify spam. Using its rule base, it uses a wide range of advanced heuristic and statistical analysis tests on mail headers and body text to identify \"spam\", also known as unsolicited bulk email. Once identified, the mail can then be optionally tagged as spam for later filtering. It provides a command line tool to perform filtering, a client-server system to filter large volumes of mail, and Mail::SpamAssassin, a set of Perl modules.",
        "homepage": "https://spamassassin.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "mail",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Spark",
        "description": "Apache Spark is a fast and general engine for large-scale data processing. It offers high-level APIs in Java, Scala, Python and R, as well as a rich set of libraries including stream processing, machine learning, and graph analytics.",
        "homepage": "http://spark.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Steve",
        "description": "Apache STeVe is a collection of online voting tools, used by the ASF, to handle STV and other voting methods.",
        "homepage": "http://steve.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Storm",
        "description": "Apache Storm is a distributed real-time computation system. Similar to how Hadoop provides a set of general primitives for doing batch processing, Storm provides a set of general primitives for doing real-time computation.",
        "homepage": "http://storm.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Struts",
        "description": "The Apache Struts Project offers the Apache Struts 2 web framework which is a comprehensive and modular tooling stack for creating web-based Java applications. Struts 2, emerged from the WebWork 2 framework, is an excellent choice for teams who value elegant solutions to difficult problems. ",
        "homepage": "http://struts.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Subversion",
        "description": "Subversion exists to be universally recognized and adopted as an open-source, centralized version control system characterized by its reliability as a safe haven for valuable data; the simplicity of its model and usage; and its ability to support the needs of a wide variety of users and projects, from individuals to large-scale enterprise operations.",
        "homepage": "http://subversion.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Superset",
        "description": "Superset is a fast, lightweight, intuitive, business intelligence platform. Loaded with options, Superset makes it easy for users of all skill sets to explore and visualize their data, from simple line charts to highly detailed geospatial charts.\n\n* Powerful yet easy to use:\nSuperset makes it easy to explore your data, using either our simple no-code viz builder or state-of-the-art SQL IDE.\n\n* Integrates with modern databases\nSuperset can connect to any SQL-based databases including modern cloud-native databases and engines at petabyte scale.\n\n* Modern architecture\nSuperset is lightweight and highly scalable, leveraging the power of your existing data infrastructure without requiring yet another ingestion layer.\n\n* Rich visualizations and dashboards\nSuperset ships with 40+ pre-installed visualization types. Our plug-in architecture makes it easy to build custom visualizations.\n\n",
        "homepage": "https://superset.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database, data-engineering, geospatial",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Synapse",
        "description": "Apache Synapse is a simple and highly effective ESB, Web Services intermediary and SOA framework. It can be\nadded to your existing network very simply either as a services gateway or as an HTTP proxy. Once Apache\nSynapse is mediating your service requests it can perform many functions including routing, load-balancing,\ntransformation and protocol switching. Apache Synapse can be used to build an Enterprise Service Bus (ESB) or\nService Oriented Architecture (SOA).\n\nApache Synapse has been designed to support very fast XML routing with a streaming XML design based upon\nApache Axiom. in addition, the use of a completely asynchronous architecture and non-blocking IO based on Java NIO\nensures that Synapse has very low overhead and can scale to support thousands of concurrent clients without dropping\nmessages.",
        "homepage": "http://synapse.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml, http, network-server, network-client",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Syncope",
        "description": "Apache Syncope is an Open Source system for managing digital identities in enterprise environments, implemented in Java EE technology and released under Apache 2.0 license.\n\nIdentity management (or IdM) represents the joint result of business process and IT to manage user data on systems and applications. IdM involves considering user attributes, roles, resources and entitlements in trying to give a decent answer to the question bumping at every time in IT administrators' mind:\n\nWho has access to What, When, How, and Why?",
        "homepage": "http://syncope.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "identity-management, identity-provisioning, security",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tapestry",
        "description": "Tapestry is a component-oriented Java web application framework.\n    Its design emphasizes ease of use and developer productivity. Component\n    classes are simple POJOs, with Tapestry using byte code manipulation to\n    enhance classes at runtime. Configuration is via annotations and naming\n    conventions rather than XML. Web page and component templates use regular\n    (X)HTML that can be edited by any web designer. Live Class Reloading enables\n    you to edit Java code and immediately see results by reloading the page in\n    the web browser, resulting in a very fast \"code it - see it - fix it\" loop.\n",
        "homepage": "http://tapestry.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache rivet",
        "description": "Apache Rivet is a system for creating dynamic web content via the Tcl programming language integrated with Apache Web Server. It is designed to be fast, powerful and extensible, consume few system resources, be easy to learn, and to provide the user with a platform that can also be used for other programming tasks outside the web (GUI's, system administration tasks, text processing, database manipulation, XML, and so on). In order to meet these goals Tcl programming language was chosen to combine with the Apache HTTP Server.",
        "homepage": "https://tcl.apache.org/rivet",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Websh",
        "description": "Websh is a rapid development environment for building powerful, fast, and reliable web applications in Tcl. Websh is versatile and handles everything from HTML generation to data-base driven one-to-one page customization. Websh can be run in CGI environments and as Apache module.\n",
        "homepage": "http://tcl.apache.org/websh",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework, httpd-module",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tez",
        "description": null,
        "homepage": "http://tez.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Thrift",
        "description": "Apache Thrift allows you to define data types and service interfaces in a simple definition file. Taking that file as input, the compiler generates code to be used to easily build RPC clients and servers that communicate seamlessly across programming languages. Instead of writing a load of boilerplate code to serialize and transport your objects and invoke remote methods, you can get right down to business. ",
        "homepage": "http://thrift.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "http, library, network-client, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tika",
        "description": "The Apache Tika toolkit is an ASFv2 licensed open source tool for extracting information \n    from digital documents. Tika allows search engines, content management systems and other \n    applications that work with various kinds of digital documents to easily detect and extract \n    metadata and content from all major file formats.\n    ",
        "homepage": "https://tika.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content, library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Tomcat",
        "description": "Apache Tomcat is a web server that is an open source software\n    implementation of the Java Servlet, JavaServer Pages, Java Expression\n    Language and Java WebSocket technologies. The Java Servlet, JavaServer\n    Pages, Java Expression Language and Java WebSocket specifications are\n    developed under the Java Community Process. Apache Tomcat is developed\n    in an open and participatory environment and released under the Apache\n    License version 2.\n\n    Apache Tomcat is intended to be a collaboration of the best-of-breed\n    developers from around the world. We invite you to participate in this open\n    development project.\n\n    Apache Tomcat powers numerous large-scale, mission-critical web applications\n    across a diverse range of industries and organizations. Some of these users\n    and their stories are listed on the PoweredBy wiki page.",
        "homepage": "http://tomcat.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server, http, javaee",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache TomEE",
        "description": "Apache TomEE Web Profile delivers Servlets, JSP, JSF, JTA, JPA, CDI, Bean Validation and EJB\n              Lite. Apache TomEE Plus has all the features of TomEE with the addition of JAX-RS (RESTfull Services),\n              JAX-WS (Web Services), JMS (Java Message Service) and JCA (the Java Connector Architecture). The\n              additional functionality is delivered via Apache CXF, Apache ActiveMQ and the Geronimo Connector library",
        "homepage": "http://tomee.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Traffic Control",
        "description": "With Apache Traffic Control, operators can setup a Content Delivery Network to quickly and efficiently deliver content to their users. Traffic Control is a highly distributed, scalable and redundant solution meeting the needs of operators from small to large.",
        "homepage": "https://trafficcontrol.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content, cloud, http, network-server",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Traffic Server",
        "description": "Apache Traffic Server is fast, scalable and extensible HTTP/1.1 compliant caching proxy server. ATS can be used as a reverse, forward or even transparent HTTP proxy.\n    ",
        "homepage": "https://trafficserver.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "http",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache TsFile",
        "description": "TsFile is a columnar storage file format designed for time series data, which supports efficient compression, high throughput of read and write, and compatibility with various frameworks, such as Spark and Flink. It is easy to integrate TsFile into IoT big data processing frameworks.",
        "homepage": "https://tsfile.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data, database, iot",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Turbine",
        "description": " Turbine is a servlet based framework that allows experienced Java developers to quickly build web applications. Turbine allows you to use personalize the web sites and to use user logins to restrict access to parts of your application.\n\nTurbine is a matured and well established framework that is used as the base of many other projects (like e.g. the excellent Jetspeed 1 Portals framework.\n\nTurbine is an excellent choice for developing applications that make use of a services-oriented architecture. Some of the functionality provided with Turbine includes a security management system, a scheduling service, XML-defined form validation server, and an XML-RPC service for web services. It is a simple task to create new services particular to your application.\n\nThe Turbine core is free of any dependency on a presentation layer technology. Both JavaServer Pages (JSP) and Velocity are supported inside Turbine. For developers already familiar with JSP, or have existing JSP tag libraries, Turbine offers support for the Sun standard. Velocity is the favorite view technology of most users of the Turbine framework; try it out and see if Velocity can help you develop your web applications faster and work more easily with non-programming designers.\n\nTurbine is developed in an open, participatory environment and released under the Apache Software License. Turbine is intended to be a collaboration of the best-of-breed developers from around the world. We invite you to participate in this open development project. To learn more about getting involved, look at our \"How to Help\" pages. ",
        "homepage": "http://turbine.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache TVM",
        "description": "Apache TVM is an open source machine learning compiler framework for CPUs, GPUs, and machine learning accelerators. It aims to enable machine learning engineers to optimize and run computations efficiently on any hardware backend.",
        "homepage": "https://tvm.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache UIMA",
        "description": "The Apache UIMA project supports\n      the community working on the analysis of unstructured information\n      with a unifying Java and C++ framework, tooling,\n      and analysis components, guided by the OASIS UIMA standard.\n      It includes support for very large scaleout using networked\n      clusters of compute nodes.",
        "homepage": "http://uima.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": [],
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Unomi",
        "description": "Apache Unomi is a REST server that manages user profiles and events related to the profiles. It can be used to integrate personalization and profile management within very different systems such as CMS, CRMs, Issue Trackers, native mobile application. It was designed to be easy to integrate with external systems, promoting profile sharing and re-use in very different applications.\n\nBasically the server tracks users using different mechanisms (by default cookies), builds a progressively populated profile and associates events that are performed by a user with his profile. Events may range from a click on a page, to a file being downloaded, a native mobile application button being clicked, or anything that can be sent to the server.\n\nThe server has a built-in rule system that makes it possible to perform any action when an event is collected for a profile. It also has the notion of user segments, making it possible to classify user profiles into dynamic sub-groups, notably to build personalized experiences for specific segments.",
        "homepage": "https://unomi.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "search",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache VCL",
        "description": "VCL is a modular cloud computing platform which dynamically provisions and brokers remote access to compute resources including virtual machines, bare-metal computers, and resources in other cloud platforms. A self-service web portal is used to request resources and for administration.",
        "homepage": "http://vcl.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Velocity",
        "description": "Velocity is a Java-based template engine. It permits anyone to use a simple yet powerful template language to reference objects defined in Java code.\n\nWhen Velocity is used for web development, Web designers can work in parallel with Java programmers to develop web sites according to the Model-View-Controller (MVC) model, meaning that web page designers can focus solely on creating a site that looks good, and programmers can focus solely on writing top-notch code. Velocity separates Java code from the web pages, making the web site more maintainable over its lifespan and providing a viable alternative to Java Server Pages (JSPs) or PHP. ",
        "homepage": "http://velocity.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Anakia",
        "description": "Anakia is an XML transformation tool that uses JDOM and Velocity to transform XML documents into the format of your choice. It provides an alternative to using Ant's style task and XSL to process XML files.",
        "homepage": "http://velocity.apache.org/anakia/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Velocity DVSL",
        "description": "DVSL (Declarative Velocity Style Language) is a tool modeled after XSLT and is intended for general XML transformations using the Velocity Template Language as the templating language for the transformations. The key differences are that it incorporates easy access to Java objects and allows you to use the Velocity template language and it's features for expressing the transformation templates.",
        "homepage": "http://velocity.apache.org/dvsl/devel/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Texen",
        "description": "Texen is a general purpose text generating utility. It is capable of producing almost any sort of text output. Driven by Ant, essentially an Ant Task, Texen uses a control template, an optional set of worker templates, and control context to govern the generated output. Although TexenTask can be used directly, it is usually subclassed to initialize your control context before generating any output.",
        "homepage": "http://velocity.apache.org/texen/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Velocity Tools",
        "description": "VelocityTools is a collection of Velocity subprojects with a common goal of creating tools and infrastructure for building both web and non-web applications using the Velocity template engine.",
        "homepage": "http://velocity.apache.org/velocity/tools/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Axiom",
        "description": "Apache Axiom is a StAX-based, XML Infoset compliant object model which supports on-demand building of the object tree. It supports a novel \"pull-through\" model which allows one to turn off the tree building and directly access the underlying pull event stream. It also has built in support for XML Optimized Packaging (XOP) and MTOM, the combination of which allows XML to carry binary data efficiently and in a transparent manner. The combination of these is an easy to use API with a very high performant architecture!",
        "homepage": "http://ws.apache.org/axiom/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "library, xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Woden",
        "description": "The Woden project is a subproject of the Apache Web Services Project to develop a Java class library for reading, manipulating, creating and writing WSDL documents, initially to support WSDL 2.0 but with the longer term aim of supporting past, present and future versions of WSDL.\n\nThere are two main deliverables: an API and an implementation. The Woden API will consist of a set of Java interfaces. The WSDL 2.0-specific portion of the Woden API will conform to the W3C WSDL 2.0 specification. The implementation will be a high performance implementation directly usable in other Apache projects such as Axis2.\n",
        "homepage": "http://ws.apache.org/woden/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Whimsy",
        "description": "The production Whimsy server also has a number of tools that automate some organizational processes,\n    like adding PMC members to official corporate rosters or reading, updating, and approving the monthly board agenda.",
        "homepage": "http://whimsy.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "content",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Wicket",
        "description": "Write maintainable, secure and scalable web applications using just Java and HTML. Invented in 2004, Wicket is one of the few survivors of the Java serverside web framework wars of the mid 2000's, and a proud member of the Apache Software Foundation.",
        "homepage": "http://wicket.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "web-framework",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Xalan for C++ XSLT Processor",
        "description": "Xalan-C++ is an XSLT processor for transforming XML documents into HTML, \n     text, or other XML document types. It implements XSL Transformations (XSLT) \n     Version 1.0 and XML Path Language (XPath) Version 1.0 and can be used from the \n     command line.",
        "homepage": "http://xalan.apache.org/xalan-c",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Xalan for Java XSLT Processor",
        "description": "\n     Xalan-J is an XSLT processor for transforming XML documents into HTML, text, or other XML document\n     types. It implements XSL Transformations (XSLT) Version 1.0 and XML Path Language (XPath) Version 1.0\n     and can be used from the command line, in an applet or a servlet, or as a module in other program.\n     Xalan-J implements the javax.xml.transform interface in Java API for XML Processing (JAXP) 1.3. This\n     interface provides a modular framework and a standard API for performing XML transformations, and\n     utilizes system properties to determine which Transformer and which XML parser to use.\n    ",
        "homepage": "http://xalan.apache.org/xalan-j/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Xerces for C++ XML Parser",
        "description": "\n     Xerces-C++ is a validating XML parser written in a portable subset of C++. Xerces-C++ makes it easy to give your application the ability to read and write XML data. A shared library is provided for parsing, generating, manipulating, and validating XML documents.\n     Xerces-C++ is faithful to the XML 1.0 and 1.1 recommendations and many associated standards.\n     The parser provides high performance, modularity, and scalability. Source code, samples and API documentation are provided with the parser. For portability, care has been taken to make minimal use of templates, no RTTI, and minimal use of #ifdefs.\n    ",
        "homepage": "http://xerces.apache.org/xerces-c/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Xerces for Java XML Parser",
        "description": "  \n     Xerces-J is a high performance, fully compliant validating XML parser written in Java. It is a fully conforming XML Schema processor that includes a complete implementation of the Document Object Model Level 3 Core and Load/Save W3C Recommendations and provides a complete implementation of the XML Inclusions (XInclude) W3C Recommendation. It also provides support for OASIS XML Catalogs v1.1. \n     Xerces 2.x introduced the Xerces Native Interface (XNI), a complete framework for building parser components and configurations that is extremely modular and easy to program. XNI is merely an internal set of interfaces. There is no need for an XML application programmer to learn XNI if they only intend to interface to the Xerces2 parser using standard interfaces like JAXP, DOM, and SAX. Xerces developers and application developers that need more power and flexibility than that provided by the standard interfaces should read and understand XNI.\n     The latest Xerces-J version released is, 2.12.2.\n    ",
        "homepage": "http://xerces.apache.org/xerces2-j/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Xerces for Perl XML Parser",
        "description": " XML::Xerces is the Perl API to the Apache project's Xerces XML parser. It is implemented using the Xerces C++ API, and it provides access to most of the C++ API from Perl.\n    Because it is based on Xerces-C, XML::Xerces provides a validating XML parser that makes it easy to give your application the ability to read and write XML data. Classes are provided for parsing, generating, manipulating, and validating XML documents. XML::Xerces is faithful to the XML 1.0 and 1.1 recommendations and associated standards (DOM levels 1, 2, and 3, SAX 1 and 2, Namespaces, and W3C XML Schema). The parser provides high performance, modularity, and scalability, and provides full support for Unicode.\n    XML::Xerces implements the vast majority of the Xerces-C API (if you notice any discrepancies please mail the list). The exception is some functions in the C++ API which either have better Perl counterparts (such as file I/O) or which manipulate internal C++ information that has no role in the Perl module.\n    The majority of the API is created automatically using Simplified Wrapper Interface Generator (SWIG). However, care has been taken to make most method invocations natural to perl programmers, so a number of rough C++ edges have been smoothed over (See the Special Perl API Features section). ",
        "homepage": "http://xerces.apache.org/xerces-p",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache XML Commons External",
        "description": "The External components portion of Apache XML Commons contains interfaces that are defined by external standards organizations. For DOM, that's the W3C; for SAX it's David Megginson (http://www.saxproject.org); for JAXP it's Sun. While we could send users to each of the primary sources for these deliverables, keeping our own versions of these in the XML Commons repository gives us a number of advantages: 1) Simplicity of downloads; users get the whole product from one place, 2) Better version control; we can only take fixes we want and add Apache-specific changes, 3) Better overview documentation of how these interfaces fit into the XML processing world, 4) More chance for cross-project community building within Apache projects.",
        "homepage": "http://xerces.apache.org/xml-commons/components/external/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache XML Commons Resolver",
        "description": "The XML Commons Resolver can be used in a wide variety of XML parsing, processing and related programs to resolve various public or system identifiers into accessible URLs for use by your application.  The resolver supports several catalog types for mapping, including OASIS XML, OASIS TR 9401 and XCatalog styles.",
        "homepage": "http://xerces.apache.org/xml-commons/components/resolver/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Batik",
        "description": "Batik is a Java-based toolkit for applications or applets to use images in the Scalable Vector Graphics (SVG) format for various purposes, such as display, generation and manipulation.",
        "homepage": "http://xmlgraphics.apache.org/batik/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml, graphics",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache FOP",
        "description": "FOP (Formatting Objects Processor) is the world's first print formatter driven by XSL formatting objects (XSL-FO) and the world's first output independent formatter. It is a Java application that reads a formatting object (FO) tree and renders the resulting pages to a specified output. Output formats  currently supported include PDF, PCL, PS, SVG, XML (area tree representation), Print, AWT, MIF and TXT. The primary output target is PDF.",
        "homepage": "http://xmlgraphics.apache.org/fop",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "xml, graphics",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache XML Graphics Commons",
        "description": "Apache XML Graphics Commons is a library that consists of several reusable components used by Apache Batik and Apache FOP. Many of these components can easily be used separately outside the domains of SVG and XSL-FO. You will find components such as a PDF library, an RTF library, Graphics2D implementations that let you generate PDF and PostScript files and much more.",
        "homepage": "http://xmlgraphics.apache.org/commons/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "graphics",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Yetus",
        "description": "A collection of libraries and tools that enable contribution and release processes for software projects.",
        "homepage": "https://yetus.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "build-management, library, testing",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache YuniKorn",
        "description": "N/A",
        "homepage": "https://yunikorn.apache.org",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "cloud",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache Zeppelin",
        "description": "Zeppelin is a modern web-based tool for the data scientists to collaborate over large-scale data exploration and visualization projects. ",
        "homepage": "http://zeppelin.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "big-data",
        "mailing_list": [],
        "sponsor": "N/A"
    },
    {
        "name": "Apache ZooKeeper",
        "description": "Apache ZooKeeper is an effort to develop and maintain an open-source server which enables highly reliable distributed coordination.",
        "homepage": "https://zookeeper.apache.org/",
        "status": "N/A",
        "start_date": "N/A",
        "end_date": "N/A",
        "category": "database",
        "mailing_list": [],
        "sponsor": "N/A"
    }
]